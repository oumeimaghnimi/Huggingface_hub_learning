{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Big_Transfer-timm_version2",
      "provenance": [],
      "collapsed_sections": [
        "mRR-pyhjYYax",
        "gOefTQmpYYbK",
        "jy2RJFAgYYbV",
        "bJYJpbQ7YYcc"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oumeimaghnimi/Huggingface_hub_learning/blob/master/Copie_de_Big_Transfer_timm_version2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-mdMSdBYYXt"
      },
      "source": [
        "This notebook tries to instantiate the code sample of timm repository:\n",
        "https://rwightman.github.io/pytorch-image-models/models/big-transfer/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJkkvwtmeSKl"
      },
      "source": [
        "!pip install  datasets transformers[sentencepiece]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7r1XXs-kAnW"
      },
      "source": [
        "!python -m pip install --upgrade pip; pip install git-lfs\n",
        "#git lfs install\n",
        "!apt-get install git-lfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUt0-iW8uaDW"
      },
      "source": [
        "!git config --global user.email \"oumeimaghnimi29@gmail.com\"\n",
        "!git config --global user.name \"oumeima\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU8OK--uuPQZ",
        "outputId": "2f5d6d50-fda7-4ed6-f4d2-6019c7e13b33"
      },
      "source": [
        "!huggingface-cli login\n",
        "#!transformers-cli login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        \n",
            "Username: oumeima\n",
            "Password: \n",
            "Login successful\n",
            "Your token: IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk \n",
            "\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1e12HQX-Cs4"
      },
      "source": [
        "!huggingface-cli repo create test_timm_succeed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjAPFJ9n_cbU",
        "outputId": "008b45f8-d7b0-4fce-f573-fba9cabf24ba"
      },
      "source": [
        " !git clone https://huggingface.co/oumeima/test_timm_succeed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'test_timm_succeed'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0)\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmaO0wgl_mI4",
        "outputId": "a2c0d3d3-cc24-4563-b7a6-f67ff9e871f7"
      },
      "source": [
        "!cd test_timm_succeed && ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Big Transfer (BiT)_timm_test_to_huggingface.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMGVTtdQWazK",
        "outputId": "27884368-bdcb-4332-ed87-25fe855b7203"
      },
      "source": [
        "!huggingface-cli  whoami  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "oumeima\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luyyKvrtMtyo",
        "outputId": "413620be-d1b4-446f-b5d0-c019849f0011"
      },
      "source": [
        "!cd /content/test_timm_succeed; git add . ; git status;   git commit -m \"First pretrained BiT version\",\n",
        "!cd /content/test_timm_succeed; git push  \"https://IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk@https://huggingface.co/oumeima /test-timm-succeed.git\"\n",
        "\n",
        "#!cd /content/test_timm_succeed; set :repository,  \"https://IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk@https://huggingface.co/oumeima /application.git\"; git push\n",
        "#!cd /content/test_timm_succeed; git push -f origin main  \n",
        "#\"https://IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk@https://huggingface.co/oumeima \n",
        "\n",
        "#git lfs status, \n",
        "\n",
        " #set :repository,  \"https://<OAuthToken>@github.com/username/application.git\"\n",
        " #git push \"https://$GITHUB_ACTOR:$GITHUB_TOKEN@github.com/$INPUT_REPO.git\" gh-pages\n",
        "#https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners#github_token-secret:\n",
        " #Hey, I was able to get this working.  Here is an example: https://github.com/pkgjs/gh-pages/blob/master/entrypoint.sh Basically there are two environment vars you can use GITHUB_ACTOR and GITHUB_TOKEN.  Then use the https push url.  To get the token passed in you need to use the secrets as documen…"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "fatal: unable to access 'https://IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk@https://huggingface.co/oumeima /test-timm-succeed.git/': Could not resolve host: https\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9jFonjxPMi5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "S26uqAuDCTuJ",
        "outputId": "2ee449e9-5e7c-4b63-a90c-e322a1a9891d"
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7q8dNsoekLB",
        "outputId": "214c4bf8-eda7-4d44-88d0-301d6f644e0f"
      },
      "source": [
        "!pip install  timm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 376 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu102)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCiBDhbHfOYq"
      },
      "source": [
        "import timm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4vM5FX9_zDq",
        "outputId": "07c32856-1d6f-4e9e-805b-0b85dd0c44c2"
      },
      "source": [
        "\n",
        "#in timm. _init_ #from .models import create_model, list_models, is_model, list_modules, model_entrypoint, \\\n",
        "   # is_scriptable, is_exportable, set_scriptable, set_exportable, has_model_default_key, is_model_default_key, \\\n",
        "    # get_model_default_value, is_model_pretrained\"'\n",
        "\n",
        " #timm.models._init_#   from .registry import register_model, model_entrypoint, list_models, is_model, list_modules, is_model_in_modules,\\\n",
        "    #has_model_default_key, is_model_default_key, get_model_default_value, is_model_pretrained\n",
        "\n",
        "\n",
        "import timm\n",
        "from pprint import pprint\n",
        "model_names = timm.list_models(pretrained=True)\n",
        "pprint(model_names)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['adv_inception_v3',\n",
            " 'cait_m36_384',\n",
            " 'cait_m48_448',\n",
            " 'cait_s24_224',\n",
            " 'cait_s24_384',\n",
            " 'cait_s36_384',\n",
            " 'cait_xs24_384',\n",
            " 'cait_xxs24_224',\n",
            " 'cait_xxs24_384',\n",
            " 'cait_xxs36_224',\n",
            " 'cait_xxs36_384',\n",
            " 'coat_lite_mini',\n",
            " 'coat_lite_small',\n",
            " 'coat_lite_tiny',\n",
            " 'coat_mini',\n",
            " 'coat_tiny',\n",
            " 'convit_base',\n",
            " 'convit_small',\n",
            " 'convit_tiny',\n",
            " 'cspdarknet53',\n",
            " 'cspresnet50',\n",
            " 'cspresnext50',\n",
            " 'deit_base_distilled_patch16_224',\n",
            " 'deit_base_distilled_patch16_384',\n",
            " 'deit_base_patch16_224',\n",
            " 'deit_base_patch16_384',\n",
            " 'deit_small_distilled_patch16_224',\n",
            " 'deit_small_patch16_224',\n",
            " 'deit_tiny_distilled_patch16_224',\n",
            " 'deit_tiny_patch16_224',\n",
            " 'densenet121',\n",
            " 'densenet161',\n",
            " 'densenet169',\n",
            " 'densenet201',\n",
            " 'densenetblur121d',\n",
            " 'dla34',\n",
            " 'dla46_c',\n",
            " 'dla46x_c',\n",
            " 'dla60',\n",
            " 'dla60_res2net',\n",
            " 'dla60_res2next',\n",
            " 'dla60x',\n",
            " 'dla60x_c',\n",
            " 'dla102',\n",
            " 'dla102x',\n",
            " 'dla102x2',\n",
            " 'dla169',\n",
            " 'dm_nfnet_f0',\n",
            " 'dm_nfnet_f1',\n",
            " 'dm_nfnet_f2',\n",
            " 'dm_nfnet_f3',\n",
            " 'dm_nfnet_f4',\n",
            " 'dm_nfnet_f5',\n",
            " 'dm_nfnet_f6',\n",
            " 'dpn68',\n",
            " 'dpn68b',\n",
            " 'dpn92',\n",
            " 'dpn98',\n",
            " 'dpn107',\n",
            " 'dpn131',\n",
            " 'eca_nfnet_l0',\n",
            " 'eca_nfnet_l1',\n",
            " 'eca_nfnet_l2',\n",
            " 'ecaresnet26t',\n",
            " 'ecaresnet50d',\n",
            " 'ecaresnet50d_pruned',\n",
            " 'ecaresnet50t',\n",
            " 'ecaresnet101d',\n",
            " 'ecaresnet101d_pruned',\n",
            " 'ecaresnet269d',\n",
            " 'ecaresnetlight',\n",
            " 'efficientnet_b0',\n",
            " 'efficientnet_b1',\n",
            " 'efficientnet_b1_pruned',\n",
            " 'efficientnet_b2',\n",
            " 'efficientnet_b2_pruned',\n",
            " 'efficientnet_b3',\n",
            " 'efficientnet_b3_pruned',\n",
            " 'efficientnet_b4',\n",
            " 'efficientnet_el',\n",
            " 'efficientnet_el_pruned',\n",
            " 'efficientnet_em',\n",
            " 'efficientnet_es',\n",
            " 'efficientnet_es_pruned',\n",
            " 'efficientnet_lite0',\n",
            " 'efficientnetv2_rw_m',\n",
            " 'efficientnetv2_rw_s',\n",
            " 'ens_adv_inception_resnet_v2',\n",
            " 'ese_vovnet19b_dw',\n",
            " 'ese_vovnet39b',\n",
            " 'fbnetc_100',\n",
            " 'gernet_l',\n",
            " 'gernet_m',\n",
            " 'gernet_s',\n",
            " 'ghostnet_100',\n",
            " 'gluon_inception_v3',\n",
            " 'gluon_resnet18_v1b',\n",
            " 'gluon_resnet34_v1b',\n",
            " 'gluon_resnet50_v1b',\n",
            " 'gluon_resnet50_v1c',\n",
            " 'gluon_resnet50_v1d',\n",
            " 'gluon_resnet50_v1s',\n",
            " 'gluon_resnet101_v1b',\n",
            " 'gluon_resnet101_v1c',\n",
            " 'gluon_resnet101_v1d',\n",
            " 'gluon_resnet101_v1s',\n",
            " 'gluon_resnet152_v1b',\n",
            " 'gluon_resnet152_v1c',\n",
            " 'gluon_resnet152_v1d',\n",
            " 'gluon_resnet152_v1s',\n",
            " 'gluon_resnext50_32x4d',\n",
            " 'gluon_resnext101_32x4d',\n",
            " 'gluon_resnext101_64x4d',\n",
            " 'gluon_senet154',\n",
            " 'gluon_seresnext50_32x4d',\n",
            " 'gluon_seresnext101_32x4d',\n",
            " 'gluon_seresnext101_64x4d',\n",
            " 'gluon_xception65',\n",
            " 'gmixer_24_224',\n",
            " 'gmlp_s16_224',\n",
            " 'hardcorenas_a',\n",
            " 'hardcorenas_b',\n",
            " 'hardcorenas_c',\n",
            " 'hardcorenas_d',\n",
            " 'hardcorenas_e',\n",
            " 'hardcorenas_f',\n",
            " 'hrnet_w18',\n",
            " 'hrnet_w18_small',\n",
            " 'hrnet_w18_small_v2',\n",
            " 'hrnet_w30',\n",
            " 'hrnet_w32',\n",
            " 'hrnet_w40',\n",
            " 'hrnet_w44',\n",
            " 'hrnet_w48',\n",
            " 'hrnet_w64',\n",
            " 'ig_resnext101_32x8d',\n",
            " 'ig_resnext101_32x16d',\n",
            " 'ig_resnext101_32x32d',\n",
            " 'ig_resnext101_32x48d',\n",
            " 'inception_resnet_v2',\n",
            " 'inception_v3',\n",
            " 'inception_v4',\n",
            " 'legacy_senet154',\n",
            " 'legacy_seresnet18',\n",
            " 'legacy_seresnet34',\n",
            " 'legacy_seresnet50',\n",
            " 'legacy_seresnet101',\n",
            " 'legacy_seresnet152',\n",
            " 'legacy_seresnext26_32x4d',\n",
            " 'legacy_seresnext50_32x4d',\n",
            " 'legacy_seresnext101_32x4d',\n",
            " 'levit_128',\n",
            " 'levit_128s',\n",
            " 'levit_192',\n",
            " 'levit_256',\n",
            " 'levit_384',\n",
            " 'mixer_b16_224',\n",
            " 'mixer_b16_224_in21k',\n",
            " 'mixer_b16_224_miil',\n",
            " 'mixer_b16_224_miil_in21k',\n",
            " 'mixer_l16_224',\n",
            " 'mixer_l16_224_in21k',\n",
            " 'mixnet_l',\n",
            " 'mixnet_m',\n",
            " 'mixnet_s',\n",
            " 'mixnet_xl',\n",
            " 'mnasnet_100',\n",
            " 'mobilenetv2_100',\n",
            " 'mobilenetv2_110d',\n",
            " 'mobilenetv2_120d',\n",
            " 'mobilenetv2_140',\n",
            " 'mobilenetv3_large_100',\n",
            " 'mobilenetv3_large_100_miil',\n",
            " 'mobilenetv3_large_100_miil_in21k',\n",
            " 'mobilenetv3_rw',\n",
            " 'nasnetalarge',\n",
            " 'nf_regnet_b1',\n",
            " 'nf_resnet50',\n",
            " 'nfnet_l0',\n",
            " 'pit_b_224',\n",
            " 'pit_b_distilled_224',\n",
            " 'pit_s_224',\n",
            " 'pit_s_distilled_224',\n",
            " 'pit_ti_224',\n",
            " 'pit_ti_distilled_224',\n",
            " 'pit_xs_224',\n",
            " 'pit_xs_distilled_224',\n",
            " 'pnasnet5large',\n",
            " 'regnetx_002',\n",
            " 'regnetx_004',\n",
            " 'regnetx_006',\n",
            " 'regnetx_008',\n",
            " 'regnetx_016',\n",
            " 'regnetx_032',\n",
            " 'regnetx_040',\n",
            " 'regnetx_064',\n",
            " 'regnetx_080',\n",
            " 'regnetx_120',\n",
            " 'regnetx_160',\n",
            " 'regnetx_320',\n",
            " 'regnety_002',\n",
            " 'regnety_004',\n",
            " 'regnety_006',\n",
            " 'regnety_008',\n",
            " 'regnety_016',\n",
            " 'regnety_032',\n",
            " 'regnety_040',\n",
            " 'regnety_064',\n",
            " 'regnety_080',\n",
            " 'regnety_120',\n",
            " 'regnety_160',\n",
            " 'regnety_320',\n",
            " 'repvgg_a2',\n",
            " 'repvgg_b0',\n",
            " 'repvgg_b1',\n",
            " 'repvgg_b1g4',\n",
            " 'repvgg_b2',\n",
            " 'repvgg_b2g4',\n",
            " 'repvgg_b3',\n",
            " 'repvgg_b3g4',\n",
            " 'res2net50_14w_8s',\n",
            " 'res2net50_26w_4s',\n",
            " 'res2net50_26w_6s',\n",
            " 'res2net50_26w_8s',\n",
            " 'res2net50_48w_2s',\n",
            " 'res2net101_26w_4s',\n",
            " 'res2next50',\n",
            " 'resmlp_12_224',\n",
            " 'resmlp_12_distilled_224',\n",
            " 'resmlp_24_224',\n",
            " 'resmlp_24_distilled_224',\n",
            " 'resmlp_36_224',\n",
            " 'resmlp_36_distilled_224',\n",
            " 'resmlp_big_24_224',\n",
            " 'resmlp_big_24_224_in22ft1k',\n",
            " 'resmlp_big_24_distilled_224',\n",
            " 'resnest14d',\n",
            " 'resnest26d',\n",
            " 'resnest50d',\n",
            " 'resnest50d_1s4x24d',\n",
            " 'resnest50d_4s2x40d',\n",
            " 'resnest101e',\n",
            " 'resnest200e',\n",
            " 'resnest269e',\n",
            " 'resnet18',\n",
            " 'resnet18d',\n",
            " 'resnet26',\n",
            " 'resnet26d',\n",
            " 'resnet34',\n",
            " 'resnet34d',\n",
            " 'resnet50',\n",
            " 'resnet50d',\n",
            " 'resnet51q',\n",
            " 'resnet101d',\n",
            " 'resnet152d',\n",
            " 'resnet200d',\n",
            " 'resnetblur50',\n",
            " 'resnetrs50',\n",
            " 'resnetrs101',\n",
            " 'resnetrs152',\n",
            " 'resnetrs200',\n",
            " 'resnetrs270',\n",
            " 'resnetrs350',\n",
            " 'resnetrs420',\n",
            " 'resnetv2_50x1_bit_distilled',\n",
            " 'resnetv2_50x1_bitm',\n",
            " 'resnetv2_50x1_bitm_in21k',\n",
            " 'resnetv2_50x3_bitm',\n",
            " 'resnetv2_50x3_bitm_in21k',\n",
            " 'resnetv2_101x1_bitm',\n",
            " 'resnetv2_101x1_bitm_in21k',\n",
            " 'resnetv2_101x3_bitm',\n",
            " 'resnetv2_101x3_bitm_in21k',\n",
            " 'resnetv2_152x2_bit_teacher',\n",
            " 'resnetv2_152x2_bit_teacher_384',\n",
            " 'resnetv2_152x2_bitm',\n",
            " 'resnetv2_152x2_bitm_in21k',\n",
            " 'resnetv2_152x4_bitm',\n",
            " 'resnetv2_152x4_bitm_in21k',\n",
            " 'resnext50_32x4d',\n",
            " 'resnext50d_32x4d',\n",
            " 'resnext101_32x8d',\n",
            " 'rexnet_100',\n",
            " 'rexnet_130',\n",
            " 'rexnet_150',\n",
            " 'rexnet_200',\n",
            " 'selecsls42b',\n",
            " 'selecsls60',\n",
            " 'selecsls60b',\n",
            " 'semnasnet_100',\n",
            " 'seresnet50',\n",
            " 'seresnet152d',\n",
            " 'seresnext26d_32x4d',\n",
            " 'seresnext26t_32x4d',\n",
            " 'seresnext50_32x4d',\n",
            " 'skresnet18',\n",
            " 'skresnet34',\n",
            " 'skresnext50_32x4d',\n",
            " 'spnasnet_100',\n",
            " 'ssl_resnet18',\n",
            " 'ssl_resnet50',\n",
            " 'ssl_resnext50_32x4d',\n",
            " 'ssl_resnext101_32x4d',\n",
            " 'ssl_resnext101_32x8d',\n",
            " 'ssl_resnext101_32x16d',\n",
            " 'swin_base_patch4_window7_224',\n",
            " 'swin_base_patch4_window7_224_in22k',\n",
            " 'swin_base_patch4_window12_384',\n",
            " 'swin_base_patch4_window12_384_in22k',\n",
            " 'swin_large_patch4_window7_224',\n",
            " 'swin_large_patch4_window7_224_in22k',\n",
            " 'swin_large_patch4_window12_384',\n",
            " 'swin_large_patch4_window12_384_in22k',\n",
            " 'swin_small_patch4_window7_224',\n",
            " 'swin_tiny_patch4_window7_224',\n",
            " 'swsl_resnet18',\n",
            " 'swsl_resnet50',\n",
            " 'swsl_resnext50_32x4d',\n",
            " 'swsl_resnext101_32x4d',\n",
            " 'swsl_resnext101_32x8d',\n",
            " 'swsl_resnext101_32x16d',\n",
            " 'tf_efficientnet_b0',\n",
            " 'tf_efficientnet_b0_ap',\n",
            " 'tf_efficientnet_b0_ns',\n",
            " 'tf_efficientnet_b1',\n",
            " 'tf_efficientnet_b1_ap',\n",
            " 'tf_efficientnet_b1_ns',\n",
            " 'tf_efficientnet_b2',\n",
            " 'tf_efficientnet_b2_ap',\n",
            " 'tf_efficientnet_b2_ns',\n",
            " 'tf_efficientnet_b3',\n",
            " 'tf_efficientnet_b3_ap',\n",
            " 'tf_efficientnet_b3_ns',\n",
            " 'tf_efficientnet_b4',\n",
            " 'tf_efficientnet_b4_ap',\n",
            " 'tf_efficientnet_b4_ns',\n",
            " 'tf_efficientnet_b5',\n",
            " 'tf_efficientnet_b5_ap',\n",
            " 'tf_efficientnet_b5_ns',\n",
            " 'tf_efficientnet_b6',\n",
            " 'tf_efficientnet_b6_ap',\n",
            " 'tf_efficientnet_b6_ns',\n",
            " 'tf_efficientnet_b7',\n",
            " 'tf_efficientnet_b7_ap',\n",
            " 'tf_efficientnet_b7_ns',\n",
            " 'tf_efficientnet_b8',\n",
            " 'tf_efficientnet_b8_ap',\n",
            " 'tf_efficientnet_cc_b0_4e',\n",
            " 'tf_efficientnet_cc_b0_8e',\n",
            " 'tf_efficientnet_cc_b1_8e',\n",
            " 'tf_efficientnet_el',\n",
            " 'tf_efficientnet_em',\n",
            " 'tf_efficientnet_es',\n",
            " 'tf_efficientnet_l2_ns',\n",
            " 'tf_efficientnet_l2_ns_475',\n",
            " 'tf_efficientnet_lite0',\n",
            " 'tf_efficientnet_lite1',\n",
            " 'tf_efficientnet_lite2',\n",
            " 'tf_efficientnet_lite3',\n",
            " 'tf_efficientnet_lite4',\n",
            " 'tf_efficientnetv2_b0',\n",
            " 'tf_efficientnetv2_b1',\n",
            " 'tf_efficientnetv2_b2',\n",
            " 'tf_efficientnetv2_b3',\n",
            " 'tf_efficientnetv2_l',\n",
            " 'tf_efficientnetv2_l_in21ft1k',\n",
            " 'tf_efficientnetv2_l_in21k',\n",
            " 'tf_efficientnetv2_m',\n",
            " 'tf_efficientnetv2_m_in21ft1k',\n",
            " 'tf_efficientnetv2_m_in21k',\n",
            " 'tf_efficientnetv2_s',\n",
            " 'tf_efficientnetv2_s_in21ft1k',\n",
            " 'tf_efficientnetv2_s_in21k',\n",
            " 'tf_inception_v3',\n",
            " 'tf_mixnet_l',\n",
            " 'tf_mixnet_m',\n",
            " 'tf_mixnet_s',\n",
            " 'tf_mobilenetv3_large_075',\n",
            " 'tf_mobilenetv3_large_100',\n",
            " 'tf_mobilenetv3_large_minimal_100',\n",
            " 'tf_mobilenetv3_small_075',\n",
            " 'tf_mobilenetv3_small_100',\n",
            " 'tf_mobilenetv3_small_minimal_100',\n",
            " 'tnt_s_patch16_224',\n",
            " 'tresnet_l',\n",
            " 'tresnet_l_448',\n",
            " 'tresnet_m',\n",
            " 'tresnet_m_448',\n",
            " 'tresnet_m_miil_in21k',\n",
            " 'tresnet_xl',\n",
            " 'tresnet_xl_448',\n",
            " 'tv_densenet121',\n",
            " 'tv_resnet34',\n",
            " 'tv_resnet50',\n",
            " 'tv_resnet101',\n",
            " 'tv_resnet152',\n",
            " 'tv_resnext50_32x4d',\n",
            " 'twins_pcpvt_base',\n",
            " 'twins_pcpvt_large',\n",
            " 'twins_pcpvt_small',\n",
            " 'twins_svt_base',\n",
            " 'twins_svt_large',\n",
            " 'twins_svt_small',\n",
            " 'vgg11',\n",
            " 'vgg11_bn',\n",
            " 'vgg13',\n",
            " 'vgg13_bn',\n",
            " 'vgg16',\n",
            " 'vgg16_bn',\n",
            " 'vgg19',\n",
            " 'vgg19_bn',\n",
            " 'visformer_small',\n",
            " 'vit_base_patch16_224',\n",
            " 'vit_base_patch16_224_in21k',\n",
            " 'vit_base_patch16_224_miil',\n",
            " 'vit_base_patch16_224_miil_in21k',\n",
            " 'vit_base_patch16_384',\n",
            " 'vit_base_patch32_224',\n",
            " 'vit_base_patch32_224_in21k',\n",
            " 'vit_base_patch32_384',\n",
            " 'vit_base_r50_s16_224_in21k',\n",
            " 'vit_base_r50_s16_384',\n",
            " 'vit_huge_patch14_224_in21k',\n",
            " 'vit_large_patch16_224',\n",
            " 'vit_large_patch16_224_in21k',\n",
            " 'vit_large_patch16_384',\n",
            " 'vit_large_patch32_224_in21k',\n",
            " 'vit_large_patch32_384',\n",
            " 'vit_large_r50_s32_224',\n",
            " 'vit_large_r50_s32_224_in21k',\n",
            " 'vit_large_r50_s32_384',\n",
            " 'vit_small_patch16_224',\n",
            " 'vit_small_patch16_224_in21k',\n",
            " 'vit_small_patch16_384',\n",
            " 'vit_small_patch32_224',\n",
            " 'vit_small_patch32_224_in21k',\n",
            " 'vit_small_patch32_384',\n",
            " 'vit_small_r26_s32_224',\n",
            " 'vit_small_r26_s32_224_in21k',\n",
            " 'vit_small_r26_s32_384',\n",
            " 'vit_tiny_patch16_224',\n",
            " 'vit_tiny_patch16_224_in21k',\n",
            " 'vit_tiny_patch16_384',\n",
            " 'vit_tiny_r_s16_p8_224',\n",
            " 'vit_tiny_r_s16_p8_224_in21k',\n",
            " 'vit_tiny_r_s16_p8_384',\n",
            " 'wide_resnet50_2',\n",
            " 'wide_resnet101_2',\n",
            " 'xception',\n",
            " 'xception41',\n",
            " 'xception65',\n",
            " 'xception71']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7MhJojPzDhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1652606-2d23-491f-e4e8-532b0d1c2c11"
      },
      "source": [
        "import timm\n",
        "from pprint import pprint\n",
        "model_names = timm.list_models('*resne*t*')\n",
        "pprint(model_names)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bat_resnext26ts',\n",
            " 'cspresnet50',\n",
            " 'cspresnet50d',\n",
            " 'cspresnet50w',\n",
            " 'cspresnext50',\n",
            " 'cspresnext50_iabn',\n",
            " 'eca_lambda_resnext26ts',\n",
            " 'ecaresnet26t',\n",
            " 'ecaresnet50d',\n",
            " 'ecaresnet50d_pruned',\n",
            " 'ecaresnet50t',\n",
            " 'ecaresnet101d',\n",
            " 'ecaresnet101d_pruned',\n",
            " 'ecaresnet200d',\n",
            " 'ecaresnet269d',\n",
            " 'ecaresnetlight',\n",
            " 'ecaresnext26t_32x4d',\n",
            " 'ecaresnext50t_32x4d',\n",
            " 'ens_adv_inception_resnet_v2',\n",
            " 'gcresnet50t',\n",
            " 'gcresnext26ts',\n",
            " 'geresnet50t',\n",
            " 'gluon_resnet18_v1b',\n",
            " 'gluon_resnet34_v1b',\n",
            " 'gluon_resnet50_v1b',\n",
            " 'gluon_resnet50_v1c',\n",
            " 'gluon_resnet50_v1d',\n",
            " 'gluon_resnet50_v1s',\n",
            " 'gluon_resnet101_v1b',\n",
            " 'gluon_resnet101_v1c',\n",
            " 'gluon_resnet101_v1d',\n",
            " 'gluon_resnet101_v1s',\n",
            " 'gluon_resnet152_v1b',\n",
            " 'gluon_resnet152_v1c',\n",
            " 'gluon_resnet152_v1d',\n",
            " 'gluon_resnet152_v1s',\n",
            " 'gluon_resnext50_32x4d',\n",
            " 'gluon_resnext101_32x4d',\n",
            " 'gluon_resnext101_64x4d',\n",
            " 'gluon_seresnext50_32x4d',\n",
            " 'gluon_seresnext101_32x4d',\n",
            " 'gluon_seresnext101_64x4d',\n",
            " 'ig_resnext101_32x8d',\n",
            " 'ig_resnext101_32x16d',\n",
            " 'ig_resnext101_32x32d',\n",
            " 'ig_resnext101_32x48d',\n",
            " 'inception_resnet_v2',\n",
            " 'lambda_resnet26t',\n",
            " 'lambda_resnet50t',\n",
            " 'legacy_seresnet18',\n",
            " 'legacy_seresnet34',\n",
            " 'legacy_seresnet50',\n",
            " 'legacy_seresnet101',\n",
            " 'legacy_seresnet152',\n",
            " 'legacy_seresnext26_32x4d',\n",
            " 'legacy_seresnext50_32x4d',\n",
            " 'legacy_seresnext101_32x4d',\n",
            " 'nf_ecaresnet26',\n",
            " 'nf_ecaresnet50',\n",
            " 'nf_ecaresnet101',\n",
            " 'nf_resnet26',\n",
            " 'nf_resnet50',\n",
            " 'nf_resnet101',\n",
            " 'nf_seresnet26',\n",
            " 'nf_seresnet50',\n",
            " 'nf_seresnet101',\n",
            " 'resnest14d',\n",
            " 'resnest26d',\n",
            " 'resnest50d',\n",
            " 'resnest50d_1s4x24d',\n",
            " 'resnest50d_4s2x40d',\n",
            " 'resnest101e',\n",
            " 'resnest200e',\n",
            " 'resnest269e',\n",
            " 'resnet18',\n",
            " 'resnet18d',\n",
            " 'resnet26',\n",
            " 'resnet26d',\n",
            " 'resnet26t',\n",
            " 'resnet34',\n",
            " 'resnet34d',\n",
            " 'resnet50',\n",
            " 'resnet50d',\n",
            " 'resnet50t',\n",
            " 'resnet51q',\n",
            " 'resnet61q',\n",
            " 'resnet101',\n",
            " 'resnet101d',\n",
            " 'resnet152',\n",
            " 'resnet152d',\n",
            " 'resnet200',\n",
            " 'resnet200d',\n",
            " 'resnetblur18',\n",
            " 'resnetblur50',\n",
            " 'resnetrs50',\n",
            " 'resnetrs101',\n",
            " 'resnetrs152',\n",
            " 'resnetrs200',\n",
            " 'resnetrs270',\n",
            " 'resnetrs350',\n",
            " 'resnetrs420',\n",
            " 'resnetv2_50',\n",
            " 'resnetv2_50d',\n",
            " 'resnetv2_50t',\n",
            " 'resnetv2_50x1_bit_distilled',\n",
            " 'resnetv2_50x1_bitm',\n",
            " 'resnetv2_50x1_bitm_in21k',\n",
            " 'resnetv2_50x3_bitm',\n",
            " 'resnetv2_50x3_bitm_in21k',\n",
            " 'resnetv2_101',\n",
            " 'resnetv2_101d',\n",
            " 'resnetv2_101x1_bitm',\n",
            " 'resnetv2_101x1_bitm_in21k',\n",
            " 'resnetv2_101x3_bitm',\n",
            " 'resnetv2_101x3_bitm_in21k',\n",
            " 'resnetv2_152',\n",
            " 'resnetv2_152d',\n",
            " 'resnetv2_152x2_bit_teacher',\n",
            " 'resnetv2_152x2_bit_teacher_384',\n",
            " 'resnetv2_152x2_bitm',\n",
            " 'resnetv2_152x2_bitm_in21k',\n",
            " 'resnetv2_152x4_bitm',\n",
            " 'resnetv2_152x4_bitm_in21k',\n",
            " 'resnext50_32x4d',\n",
            " 'resnext50d_32x4d',\n",
            " 'resnext101_32x4d',\n",
            " 'resnext101_32x8d',\n",
            " 'resnext101_64x4d',\n",
            " 'seresnet18',\n",
            " 'seresnet34',\n",
            " 'seresnet50',\n",
            " 'seresnet50t',\n",
            " 'seresnet101',\n",
            " 'seresnet152',\n",
            " 'seresnet152d',\n",
            " 'seresnet200d',\n",
            " 'seresnet269d',\n",
            " 'seresnext26d_32x4d',\n",
            " 'seresnext26t_32x4d',\n",
            " 'seresnext26tn_32x4d',\n",
            " 'seresnext50_32x4d',\n",
            " 'seresnext101_32x4d',\n",
            " 'seresnext101_32x8d',\n",
            " 'skresnet18',\n",
            " 'skresnet34',\n",
            " 'skresnet50',\n",
            " 'skresnet50d',\n",
            " 'skresnext50_32x4d',\n",
            " 'ssl_resnet18',\n",
            " 'ssl_resnet50',\n",
            " 'ssl_resnext50_32x4d',\n",
            " 'ssl_resnext101_32x4d',\n",
            " 'ssl_resnext101_32x8d',\n",
            " 'ssl_resnext101_32x16d',\n",
            " 'swsl_resnet18',\n",
            " 'swsl_resnet50',\n",
            " 'swsl_resnext50_32x4d',\n",
            " 'swsl_resnext101_32x4d',\n",
            " 'swsl_resnext101_32x8d',\n",
            " 'swsl_resnext101_32x16d',\n",
            " 'tresnet_l',\n",
            " 'tresnet_l_448',\n",
            " 'tresnet_m',\n",
            " 'tresnet_m_448',\n",
            " 'tresnet_m_miil_in21k',\n",
            " 'tresnet_xl',\n",
            " 'tresnet_xl_448',\n",
            " 'tv_resnet34',\n",
            " 'tv_resnet50',\n",
            " 'tv_resnet101',\n",
            " 'tv_resnet152',\n",
            " 'tv_resnext50_32x4d',\n",
            " 'vit_base_resnet26d_224',\n",
            " 'vit_base_resnet50_224_in21k',\n",
            " 'vit_base_resnet50_384',\n",
            " 'vit_base_resnet50d_224',\n",
            " 'vit_small_resnet26d_224',\n",
            " 'vit_small_resnet50d_s16_224',\n",
            " 'wide_resnet50_2',\n",
            " 'wide_resnet101_2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JainiVzJ7tau"
      },
      "source": [
        "load a pretrained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUVVGG5Fgj8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2abb9c97-a3d8-414e-e806-8951d5c41ce5"
      },
      "source": [
        "\n",
        "model = timm.create_model('resnetv2_101x1_bitm', pretrained=True)\n",
        "model.eval()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetV2(\n",
              "  (stem): Sequential(\n",
              "    (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (pad): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (stages): Sequential(\n",
              "    (0): ResNetStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): PreActBottleneck(\n",
              "          (downsample): DownsampleConv(\n",
              "            (conv): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (norm): Identity()\n",
              "          )\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): ResNetStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): PreActBottleneck(\n",
              "          (downsample): DownsampleConv(\n",
              "            (conv): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (norm): Identity()\n",
              "          )\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): ResNetStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): PreActBottleneck(\n",
              "          (downsample): DownsampleConv(\n",
              "            (conv): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (norm): Identity()\n",
              "          )\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (8): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (9): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (10): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (11): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (12): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (13): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (14): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (15): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (16): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (17): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (18): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (19): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (20): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (21): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (22): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): ResNetStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): PreActBottleneck(\n",
              "          (downsample): DownsampleConv(\n",
              "            (conv): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (norm): Identity()\n",
              "          )\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 2048, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 2048, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (norm): GroupNormAct(\n",
              "    32, 2048, eps=1e-05, affine=True\n",
              "    (act): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): ClassifierHead(\n",
              "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
              "    (fc): Conv2d(2048, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwx8oSjh7P1B"
      },
      "source": [
        "load and preprocess the image: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJxpNdkmhTB1"
      },
      "source": [
        "import urllib\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QrKVvIohXeQ",
        "outputId": "012b00b7-aa41-485c-84f9-c90d416b6862"
      },
      "source": [
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "img = Image.open(filename).convert('RGB')\n",
        "tensor = transform(img).unsqueeze(0) # transform and add batch dimension"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM411fEdigu5"
      },
      "source": [
        "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
        "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
        "\n",
        "  trial to correct the error:\n",
        "  https://github.com/pytorch/vision/blob/master/torchvision/transforms/transforms.py:\n",
        "  from .functional import InterpolationMode, _interpolation_modes_from_int\n",
        "\n",
        "   \n",
        "   line 281: /usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281:\n",
        "    \n",
        "                  or\n",
        "\n",
        "   line 387: in https://github.com/pytorch/vision/blob/master/torchvision/transforms/functional.py\n",
        "   \n",
        "   (it is not an error, just an information error):\n",
        "     if isinstance(interpolation, int):\n",
        "           warnings.warn(\n",
        "               \"Argument interpolation should be of type InterpolationMode      instead of int. \"\n",
        "            \"Please, use InterpolationMode enum.\"\n",
        "        )\n",
        "        interpolation = _interpolation_modes_from_int(interpolation)\n",
        "\n",
        "\n",
        "\n",
        "interpolation as an argument \n",
        "\n",
        "\n",
        "https://github.com/pytorch/vision/blob/master/torchvision/transforms/functional.py\n",
        "\n",
        "\n",
        "def _interpolation_modes_from_int(i: int) -> InterpolationMode:\n",
        "    inverse_modes_mapping = {\n",
        "        0: InterpolationMode.NEAREST,\n",
        "        2: InterpolationMode.BILINEAR,\n",
        "        3: InterpolationMode.BICUBIC,\n",
        "        4: InterpolationMode.BOX,\n",
        "        5: InterpolationMode.HAMMING,\n",
        "        1: InterpolationMode.LANCZOS,\n",
        "    }\n",
        "    return inverse_modes_mapping[i]\n",
        "\n",
        "\n",
        "pil_modes_mapping = {\n",
        "    InterpolationMode.NEAREST: 0,\n",
        "    InterpolationMode.BILINEAR: 2,\n",
        "    InterpolationMode.BICUBIC: 3,\n",
        "    InterpolationMode.BOX: 4,\n",
        "    InterpolationMode.HAMMING: 5,\n",
        "    InterpolationMode.LANCZOS: 1,\n",
        "}\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "resolve_data_config:\n",
        "    from timm.data import resolve_data_config\n",
        "    \n",
        "def resolve_data_config(args, default_cfg={}, model=None, use_test_size=False, verbose=False):\n",
        "   \n",
        "\n",
        "\n",
        "   timm/data/config.py: \n",
        "    # resolve interpolation method\n",
        "    new_config['interpolation'] = 'bicubic'\n",
        "    if 'interpolation' in args and args['interpolation']:\n",
        "        new_config['interpolation'] = args['interpolation']\n",
        "    elif 'interpolation' in default_cfg:\n",
        "        new_config['interpolation'] = default_cfg['interpolation']   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk26SvZ_MCk0"
      },
      "source": [
        "get the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_ZKGh5JMnyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2286a962-6d9f-43f2-cc30-66fc4a654780"
      },
      "source": [
        "import torch\n",
        "with torch.no_grad():\n",
        "    out = model(tensor)\n",
        "probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "print(probabilities)\n",
        "print(probabilities.shape)\n",
        "# prints: torch.Size([1000])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([8.6920e-06, 1.0017e-05, 1.4372e-05, 5.0999e-05, 4.5306e-05, 3.9800e-05,\n",
            "        9.8520e-06, 9.6706e-06, 3.3262e-05, 8.4749e-06, 8.8097e-06, 9.8926e-06,\n",
            "        4.8570e-06, 3.7003e-06, 8.8064e-06, 1.2141e-05, 4.9568e-06, 1.6457e-05,\n",
            "        6.4504e-06, 5.0538e-06, 1.0002e-05, 2.6593e-05, 7.1253e-06, 8.1279e-06,\n",
            "        5.7542e-06, 7.9966e-06, 1.7420e-05, 3.9293e-06, 5.2244e-06, 2.7674e-05,\n",
            "        7.6498e-06, 1.3327e-05, 1.1538e-05, 3.8164e-06, 3.7070e-06, 2.9407e-06,\n",
            "        9.7026e-06, 2.7875e-06, 6.1393e-06, 6.1891e-06, 5.6028e-06, 6.1973e-06,\n",
            "        5.2446e-06, 2.6525e-06, 5.7981e-06, 3.2827e-06, 1.4908e-05, 1.7386e-05,\n",
            "        2.9888e-06, 4.2177e-06, 1.1562e-05, 4.2993e-06, 3.0088e-05, 6.3115e-06,\n",
            "        9.6404e-06, 9.9693e-06, 7.5385e-06, 5.0012e-06, 1.6144e-05, 1.4105e-05,\n",
            "        1.3371e-05, 4.4746e-06, 5.4517e-06, 1.0142e-05, 2.0313e-05, 9.8770e-06,\n",
            "        1.3727e-05, 4.2800e-06, 8.9869e-06, 2.3762e-06, 1.5132e-05, 1.7925e-05,\n",
            "        6.0713e-06, 1.6020e-05, 1.5472e-05, 1.3292e-05, 4.2951e-06, 1.1696e-06,\n",
            "        1.8586e-05, 8.1992e-06, 6.3864e-06, 2.8697e-05, 7.9059e-06, 6.7815e-06,\n",
            "        1.1186e-05, 4.4537e-06, 9.7240e-06, 2.0536e-06, 5.0057e-06, 4.5628e-05,\n",
            "        5.5086e-06, 7.3256e-06, 4.8536e-06, 2.7357e-06, 8.7805e-06, 5.3317e-06,\n",
            "        2.9863e-06, 3.8958e-06, 2.4906e-05, 2.0241e-05, 1.1409e-05, 2.3186e-06,\n",
            "        3.2015e-06, 1.7451e-06, 3.4471e-05, 1.4655e-05, 1.4409e-05, 1.9334e-05,\n",
            "        2.0263e-05, 4.6027e-06, 1.8469e-05, 2.1542e-05, 1.7222e-05, 9.9348e-06,\n",
            "        1.9320e-05, 1.8847e-05, 4.7621e-06, 5.5580e-06, 3.3331e-06, 8.0920e-06,\n",
            "        8.5276e-06, 3.7758e-06, 6.2945e-06, 7.9379e-06, 6.4053e-06, 1.7923e-06,\n",
            "        6.6947e-06, 3.9827e-05, 4.0613e-06, 3.1014e-05, 1.0417e-05, 4.0851e-06,\n",
            "        5.0604e-05, 2.1685e-06, 1.6222e-05, 8.8531e-06, 1.5151e-05, 3.7597e-06,\n",
            "        4.5026e-06, 5.5277e-06, 4.7235e-06, 1.0590e-05, 1.3385e-05, 1.7490e-05,\n",
            "        2.5772e-05, 7.5074e-06, 2.2959e-05, 1.4911e-05, 2.0311e-05, 1.1702e-05,\n",
            "        9.0227e-06, 3.7392e-05, 1.4497e-03, 6.1913e-05, 2.4860e-04, 9.3635e-06,\n",
            "        8.6505e-06, 1.1308e-04, 2.8669e-05, 2.3085e-06, 1.1436e-05, 2.0085e-06,\n",
            "        2.6470e-06, 1.7572e-06, 3.0032e-06, 7.3768e-07, 2.8584e-06, 3.3710e-06,\n",
            "        3.2159e-06, 5.9224e-05, 1.1221e-05, 7.4380e-06, 2.8756e-06, 5.4319e-06,\n",
            "        3.4623e-05, 2.2216e-06, 1.7955e-06, 8.2484e-06, 2.4957e-06, 1.0812e-05,\n",
            "        7.2034e-06, 4.3005e-06, 3.3229e-06, 5.9196e-06, 7.4649e-06, 1.8740e-05,\n",
            "        1.9572e-05, 2.1863e-05, 1.0245e-04, 2.9197e-06, 1.6526e-05, 3.3654e-06,\n",
            "        1.4243e-05, 3.7785e-05, 1.0466e-05, 4.4482e-06, 6.4360e-06, 6.1260e-06,\n",
            "        5.6038e-06, 3.6118e-05, 4.8873e-05, 7.6865e-06, 5.3277e-06, 4.1228e-04,\n",
            "        1.0164e-05, 3.4513e-06, 1.5241e-06, 1.2484e-05, 6.6179e-06, 1.8755e-06,\n",
            "        5.7250e-06, 3.5824e-06, 3.3128e-05, 3.9096e-06, 5.8441e-06, 1.2191e-05,\n",
            "        4.4118e-05, 3.6804e-06, 2.8051e-06, 3.0009e-06, 1.4450e-05, 3.6817e-06,\n",
            "        3.5838e-04, 2.8096e-04, 9.8409e-04, 9.3774e-06, 2.2775e-05, 1.3345e-05,\n",
            "        4.9627e-05, 4.1621e-05, 1.4001e-04, 1.5807e-04, 5.4680e-05, 1.1682e-05,\n",
            "        2.4169e-06, 4.1859e-05, 9.2754e-06, 2.0066e-05, 3.4882e-06, 6.4105e-06,\n",
            "        1.3538e-05, 2.1506e-06, 1.4206e-05, 1.3899e-06, 9.7336e-06, 5.6179e-06,\n",
            "        1.9838e-06, 9.4647e-06, 2.1254e-03, 2.8014e-04, 3.6695e-04, 1.6137e-05,\n",
            "        1.3282e-05, 2.1826e-05, 3.2215e-06, 1.0302e-05, 1.1456e-04, 7.9546e-04,\n",
            "        9.4777e-01, 8.8784e-03, 1.3314e-03, 6.5887e-03, 1.6340e-05, 2.9780e-05,\n",
            "        5.9554e-06, 3.0287e-05, 1.7876e-05, 6.5552e-05, 4.8343e-06, 6.2239e-05,\n",
            "        5.0971e-03, 2.6192e-05, 1.2529e-05, 8.1003e-05, 9.4569e-05, 1.1746e-05,\n",
            "        1.5876e-05, 6.3558e-05, 1.3917e-05, 6.9802e-03, 6.9102e-05, 3.7015e-06,\n",
            "        6.1596e-06, 2.9297e-04, 1.4568e-05, 1.8742e-05, 5.0005e-06, 2.2949e-05,\n",
            "        8.9826e-06, 2.2384e-05, 1.0187e-05, 9.5780e-06, 6.3300e-06, 1.0147e-05,\n",
            "        6.3196e-06, 1.3425e-05, 3.2617e-05, 1.2357e-05, 4.0515e-06, 1.5615e-05,\n",
            "        9.8070e-06, 3.8840e-06, 6.7155e-06, 6.6980e-06, 1.0141e-05, 1.9695e-06,\n",
            "        6.2374e-06, 4.1508e-06, 5.7472e-06, 1.5767e-05, 2.5680e-05, 1.4541e-05,\n",
            "        8.5080e-06, 1.5814e-05, 8.1778e-06, 2.6632e-05, 5.8820e-06, 1.4185e-05,\n",
            "        1.3901e-05, 5.7947e-06, 2.3975e-05, 2.6516e-06, 1.0452e-05, 1.3287e-05,\n",
            "        1.9367e-05, 1.0706e-05, 5.1563e-06, 1.1945e-05, 1.3592e-05, 2.1912e-06,\n",
            "        6.1011e-06, 1.6214e-05, 3.3707e-04, 5.3991e-05, 1.1057e-05, 2.0365e-05,\n",
            "        1.3688e-05, 7.4203e-06, 1.1865e-05, 5.8321e-06, 5.2207e-06, 1.1083e-05,\n",
            "        2.5516e-06, 7.4220e-06, 7.8280e-06, 6.8474e-06, 2.7942e-06, 4.3940e-06,\n",
            "        8.5807e-06, 3.1556e-06, 2.7485e-06, 3.1967e-06, 3.0563e-06, 1.1143e-05,\n",
            "        8.3673e-06, 3.7999e-05, 2.9928e-05, 3.4100e-05, 1.1624e-04, 1.8988e-05,\n",
            "        2.9280e-06, 1.0009e-04, 8.3822e-06, 3.2356e-06, 4.1232e-06, 4.8379e-06,\n",
            "        9.1080e-06, 6.5711e-06, 2.9263e-05, 7.4731e-06, 8.8091e-06, 1.9421e-05,\n",
            "        1.0614e-05, 1.9763e-05, 2.8775e-05, 1.1529e-05, 3.1012e-06, 3.6327e-05,\n",
            "        1.6672e-05, 5.9848e-06, 2.0530e-05, 2.8804e-05, 1.1331e-05, 1.0828e-05,\n",
            "        3.9817e-05, 5.6719e-06, 1.2070e-06, 2.0916e-05, 2.1465e-05, 1.1042e-05,\n",
            "        8.4927e-06, 1.0931e-05, 8.1771e-06, 3.3813e-06, 5.3771e-06, 9.2662e-06,\n",
            "        4.5929e-06, 4.6241e-06, 1.9764e-06, 5.6043e-06, 5.5137e-06, 6.4335e-06,\n",
            "        6.3911e-06, 1.1524e-05, 1.4369e-05, 2.8659e-05, 1.4477e-05, 9.2996e-05,\n",
            "        9.1745e-06, 1.4217e-05, 7.3198e-06, 3.6612e-06, 2.1274e-05, 7.3493e-06,\n",
            "        6.8884e-06, 4.4598e-06, 1.7519e-05, 8.6798e-06, 1.5803e-05, 1.9170e-05,\n",
            "        8.8512e-06, 2.3273e-05, 1.3848e-05, 5.5093e-06, 1.9186e-06, 1.1560e-05,\n",
            "        1.8349e-05, 1.3244e-05, 1.2630e-05, 2.6400e-05, 8.7272e-06, 1.9958e-05,\n",
            "        1.5001e-05, 3.0926e-06, 8.2552e-06, 1.7383e-05, 8.3545e-05, 6.1590e-05,\n",
            "        4.8709e-05, 1.3995e-05, 1.1547e-05, 1.5776e-05, 3.6512e-05, 9.1903e-06,\n",
            "        1.2761e-05, 1.0613e-05, 8.9140e-06, 6.1828e-06, 2.0709e-05, 5.4792e-06,\n",
            "        4.8115e-05, 6.3239e-06, 3.9247e-06, 4.6432e-06, 4.5452e-06, 1.0726e-05,\n",
            "        1.7912e-05, 1.0329e-05, 1.7436e-05, 3.9995e-06, 4.5204e-05, 3.0291e-05,\n",
            "        2.9889e-05, 1.8253e-05, 7.8571e-06, 1.2592e-05, 5.0063e-05, 5.4185e-06,\n",
            "        1.2040e-05, 2.4572e-05, 9.4995e-05, 1.0247e-05, 4.8517e-05, 2.1495e-05,\n",
            "        4.4579e-06, 1.5156e-05, 7.7983e-06, 8.8437e-06, 1.3605e-05, 8.4903e-05,\n",
            "        7.1597e-06, 1.3084e-05, 5.7344e-06, 1.3614e-05, 1.6254e-05, 1.2704e-05,\n",
            "        1.2189e-05, 6.0433e-06, 1.0738e-05, 4.1840e-05, 4.4214e-06, 4.3399e-06,\n",
            "        3.6433e-06, 1.8740e-05, 4.7415e-06, 6.8382e-06, 1.2014e-05, 1.0174e-05,\n",
            "        6.6391e-06, 8.1961e-06, 5.0030e-06, 1.0695e-05, 1.8945e-05, 9.8795e-06,\n",
            "        1.5348e-05, 4.0202e-05, 9.6116e-06, 2.1131e-05, 1.4786e-05, 5.4423e-06,\n",
            "        8.1047e-06, 2.5700e-05, 3.0131e-06, 1.2297e-05, 4.5301e-06, 2.1359e-05,\n",
            "        1.0618e-05, 5.6560e-06, 3.1925e-05, 5.9036e-06, 7.2985e-06, 2.4224e-06,\n",
            "        4.0923e-05, 6.6142e-06, 1.0830e-05, 1.6937e-05, 1.6652e-05, 6.8465e-06,\n",
            "        8.6605e-06, 3.2528e-05, 1.0521e-05, 1.0788e-05, 1.2952e-05, 7.9439e-06,\n",
            "        1.2671e-05, 4.0006e-05, 9.8212e-07, 1.4405e-05, 5.2844e-06, 1.8721e-05,\n",
            "        5.5405e-06, 5.4107e-06, 1.3599e-05, 9.1235e-06, 7.1672e-06, 2.3354e-05,\n",
            "        2.5268e-05, 3.8430e-06, 5.8516e-06, 3.3975e-05, 4.1033e-06, 1.3373e-05,\n",
            "        8.2550e-06, 8.5085e-06, 1.6910e-05, 2.2426e-06, 1.0674e-05, 1.0987e-05,\n",
            "        7.4042e-06, 1.2648e-05, 1.8572e-05, 1.9521e-06, 9.2113e-06, 2.0179e-05,\n",
            "        1.5187e-05, 1.5904e-05, 5.8884e-06, 2.2697e-06, 1.0958e-05, 5.9494e-06,\n",
            "        1.3740e-05, 7.6978e-06, 2.2116e-05, 2.0991e-05, 6.5705e-05, 9.8759e-06,\n",
            "        9.6015e-06, 5.7114e-06, 1.9791e-05, 8.2614e-06, 4.6894e-05, 2.2132e-05,\n",
            "        6.7104e-06, 1.1062e-05, 1.1780e-05, 9.3058e-06, 1.5392e-05, 7.4218e-06,\n",
            "        4.8099e-06, 1.9717e-05, 1.0343e-05, 1.9860e-05, 5.3230e-06, 7.9869e-06,\n",
            "        1.6323e-05, 8.0348e-06, 7.0110e-06, 4.9651e-06, 2.3167e-06, 7.6292e-06,\n",
            "        2.5330e-05, 1.7345e-05, 7.9690e-06, 5.3114e-06, 1.7796e-05, 7.7718e-06,\n",
            "        9.5680e-06, 3.3041e-05, 9.3743e-06, 5.4437e-06, 1.0437e-05, 6.2479e-06,\n",
            "        2.4990e-06, 1.1163e-05, 5.3742e-06, 1.3831e-05, 5.7401e-06, 2.3023e-05,\n",
            "        5.9218e-06, 1.7379e-05, 2.3758e-06, 1.4226e-05, 1.4503e-05, 5.6444e-06,\n",
            "        2.9463e-06, 1.3658e-05, 4.1441e-05, 3.0177e-05, 1.3101e-05, 8.9844e-06,\n",
            "        1.0374e-05, 2.8295e-05, 6.0595e-06, 1.0467e-05, 3.2310e-06, 1.3956e-05,\n",
            "        3.6526e-06, 1.3763e-05, 6.9232e-06, 2.5802e-06, 3.9662e-05, 3.6662e-06,\n",
            "        4.8524e-06, 3.4655e-05, 2.1673e-05, 1.1248e-05, 9.4468e-05, 1.8745e-05,\n",
            "        1.2832e-05, 1.1206e-05, 1.5290e-05, 2.3735e-06, 2.9498e-06, 3.7156e-05,\n",
            "        3.9870e-06, 9.6069e-06, 7.6078e-06, 1.4738e-05, 1.1008e-05, 1.3841e-05,\n",
            "        6.8078e-06, 7.1830e-06, 1.9448e-05, 7.3769e-06, 1.8059e-06, 4.8897e-06,\n",
            "        1.9536e-05, 4.6256e-06, 3.0990e-05, 1.5374e-05, 2.4488e-05, 1.3748e-05,\n",
            "        9.8502e-06, 8.6548e-06, 7.0326e-06, 6.1746e-06, 1.0115e-04, 3.6092e-05,\n",
            "        4.6114e-05, 4.9300e-06, 1.0714e-04, 7.4265e-06, 2.9623e-05, 1.4904e-05,\n",
            "        1.2848e-05, 5.1915e-05, 1.6877e-04, 1.6108e-05, 1.3894e-05, 2.8627e-05,\n",
            "        3.3950e-06, 1.7063e-05, 3.1438e-05, 5.2465e-06, 7.6690e-06, 5.2416e-06,\n",
            "        7.0958e-06, 1.1541e-05, 8.3576e-06, 1.5900e-05, 3.9503e-05, 8.8848e-06,\n",
            "        6.0662e-06, 4.2669e-05, 9.2396e-06, 9.1984e-06, 9.0469e-06, 6.7035e-06,\n",
            "        2.6383e-05, 4.7410e-06, 3.6805e-06, 1.7413e-05, 1.0208e-05, 1.1602e-05,\n",
            "        1.1673e-05, 2.4133e-05, 2.0985e-05, 1.4845e-05, 1.5738e-05, 2.0738e-05,\n",
            "        7.5519e-06, 1.2011e-05, 1.0287e-05, 8.8721e-06, 2.8758e-06, 8.5914e-06,\n",
            "        4.5690e-06, 8.0838e-06, 1.1339e-05, 9.1411e-06, 5.6809e-06, 9.3989e-06,\n",
            "        3.3135e-06, 9.4765e-05, 2.0422e-05, 2.2694e-05, 1.7672e-05, 2.9391e-06,\n",
            "        2.8748e-05, 4.2848e-06, 3.4858e-06, 8.5594e-06, 1.2129e-05, 4.9751e-06,\n",
            "        9.7351e-06, 4.1524e-06, 3.4367e-05, 8.4472e-06, 1.8456e-05, 1.1762e-05,\n",
            "        1.9894e-05, 3.1147e-04, 6.5507e-05, 2.0558e-05, 9.3364e-06, 1.6135e-05,\n",
            "        2.1859e-05, 4.5102e-05, 1.2143e-05, 1.0352e-05, 1.1819e-05, 3.5579e-05,\n",
            "        3.4972e-06, 8.7609e-06, 9.7599e-06, 7.8909e-06, 4.0739e-06, 3.0362e-05,\n",
            "        7.5126e-06, 5.7285e-05, 3.6829e-05, 1.3430e-05, 7.1081e-06, 8.0210e-06,\n",
            "        9.3848e-06, 8.1137e-06, 5.4643e-06, 1.2344e-05, 9.1691e-06, 1.1582e-06,\n",
            "        1.3855e-05, 5.1803e-05, 7.0324e-06, 3.0200e-05, 4.0882e-06, 1.3380e-05,\n",
            "        2.0908e-05, 7.3105e-06, 9.3929e-06, 1.9049e-05, 4.1903e-06, 2.2708e-05,\n",
            "        6.8352e-06, 5.3630e-06, 8.3612e-06, 1.7878e-05, 1.6889e-05, 1.6224e-05,\n",
            "        1.2713e-05, 5.2526e-06, 1.5713e-05, 1.6014e-05, 4.2415e-05, 6.1009e-06,\n",
            "        9.8992e-06, 6.4816e-06, 9.5537e-06, 3.5070e-05, 6.5020e-06, 5.0155e-06,\n",
            "        1.5522e-05, 1.0550e-05, 8.3360e-06, 8.3422e-06, 3.1264e-05, 1.6760e-05,\n",
            "        8.2083e-06, 2.4683e-05, 1.7829e-05, 1.5206e-05, 9.2598e-06, 4.7412e-06,\n",
            "        4.8731e-06, 6.4745e-06, 1.2057e-05, 1.0986e-05, 3.2734e-05, 1.4209e-05,\n",
            "        1.7510e-05, 3.4430e-06, 1.4856e-05, 1.3510e-05, 2.1105e-05, 1.5945e-05,\n",
            "        2.0738e-05, 7.5708e-05, 6.0252e-06, 8.1354e-06, 2.8631e-05, 3.7620e-06,\n",
            "        1.2811e-05, 6.0319e-06, 8.1734e-06, 1.2016e-05, 5.6200e-05, 6.2569e-06,\n",
            "        6.0580e-06, 8.7049e-06, 1.0141e-05, 1.5016e-05, 5.4861e-06, 7.6447e-06,\n",
            "        1.9822e-04, 7.3107e-06, 9.6927e-06, 1.6045e-05, 3.9596e-06, 8.0728e-06,\n",
            "        9.1338e-06, 3.1462e-06, 5.0575e-06, 2.1053e-05, 2.3649e-05, 2.4349e-05,\n",
            "        1.0457e-05, 3.6071e-06, 4.1970e-06, 7.5330e-06, 1.1064e-05, 4.6022e-06,\n",
            "        1.7961e-05, 1.0734e-05, 5.4513e-06, 1.3268e-05, 8.5768e-06, 4.7346e-06,\n",
            "        4.7951e-05, 1.4408e-06, 2.5904e-06, 6.7491e-06, 1.2504e-05, 1.6682e-05,\n",
            "        1.3271e-05, 4.1558e-05, 3.2763e-05, 3.1502e-06, 8.3759e-06, 8.7476e-06,\n",
            "        5.3598e-06, 6.3847e-06, 1.1490e-05, 3.0138e-06, 2.1650e-05, 6.0893e-06,\n",
            "        1.3662e-05, 2.7024e-05, 2.4898e-05, 5.2894e-06, 1.2211e-05, 5.9472e-06,\n",
            "        1.0124e-05, 3.8061e-05, 6.3381e-06, 2.7043e-06, 7.7139e-06, 2.9674e-06,\n",
            "        6.3972e-06, 1.3631e-05, 3.2714e-05, 5.4469e-06, 5.5817e-06, 3.0911e-05,\n",
            "        2.9522e-05, 2.4257e-05, 1.2183e-05, 1.4293e-05, 7.1044e-06, 3.0734e-06,\n",
            "        3.5453e-05, 2.9935e-05, 6.2948e-06, 3.4068e-06, 7.8823e-06, 1.3467e-05,\n",
            "        5.2347e-06, 1.9178e-05, 1.0258e-05, 8.6652e-06, 3.5357e-06, 7.3557e-06,\n",
            "        5.5142e-06, 1.4824e-06, 5.6285e-06, 3.1978e-06, 4.5629e-06, 1.2790e-05,\n",
            "        3.5644e-05, 4.8762e-06, 7.3488e-06, 5.0012e-06, 7.5263e-06, 3.7071e-06,\n",
            "        1.0364e-05, 5.5589e-06, 1.1885e-05, 1.6960e-05, 6.1631e-06, 1.5295e-05,\n",
            "        9.2140e-06, 7.4986e-06, 3.7590e-06, 7.9928e-06, 1.0030e-05, 5.8549e-06,\n",
            "        6.6886e-06, 1.3649e-05, 1.2126e-05, 1.0640e-05, 6.2662e-06, 5.0868e-06,\n",
            "        6.1261e-06, 1.2093e-05, 1.6200e-06, 2.9962e-06, 3.0414e-06, 4.1849e-06,\n",
            "        2.6551e-05, 3.5133e-06, 2.1488e-05, 4.6086e-05, 1.4614e-05, 1.7738e-05,\n",
            "        3.8712e-05, 1.1440e-05, 4.8223e-05, 5.4474e-05, 1.2126e-05, 2.7866e-05,\n",
            "        2.6140e-05, 1.5741e-05, 4.0417e-05, 2.1834e-05, 4.9005e-06, 6.2414e-06,\n",
            "        1.0519e-05, 2.8768e-05, 8.8145e-06, 6.5549e-06, 6.1349e-06, 1.0379e-05,\n",
            "        8.9566e-06, 3.0837e-05, 1.7983e-05, 3.4749e-06, 2.4263e-05, 1.2980e-05,\n",
            "        7.1889e-06, 3.0217e-06, 1.2360e-05, 1.7350e-05])\n",
            "torch.Size([1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaB8thjI6Z1s",
        "outputId": "93a62fd0-7138-4a43-8ef6-6fa557c7d0b0"
      },
      "source": [
        "# Get imagenet class mappings\n",
        "import urllib\n",
        "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
        "urllib.request.urlretrieve(url, filename) \n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "    print(categories)\n",
        "    print(len(categories))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead', 'electric ray', 'stingray', 'cock', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'water ouzel', 'kite', 'bald eagle', 'vulture', 'great grey owl', 'European fire salamander', 'common newt', 'eft', 'spotted salamander', 'axolotl', 'bullfrog', 'tree frog', 'tailed frog', 'loggerhead', 'leatherback turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'common iguana', 'American chameleon', 'whiptail', 'agama', 'frilled lizard', 'alligator lizard', 'Gila monster', 'green lizard', 'African chameleon', 'Komodo dragon', 'African crocodile', 'American alligator', 'triceratops', 'thunder snake', 'ringneck snake', 'hognose snake', 'green snake', 'king snake', 'garter snake', 'water snake', 'vine snake', 'night snake', 'boa constrictor', 'rock python', 'Indian cobra', 'green mamba', 'sea snake', 'horned viper', 'diamondback', 'sidewinder', 'trilobite', 'harvestman', 'scorpion', 'black and gold garden spider', 'barn spider', 'garden spider', 'black widow', 'tarantula', 'wolf spider', 'tick', 'centipede', 'black grouse', 'ptarmigan', 'ruffed grouse', 'prairie chicken', 'peacock', 'quail', 'partridge', 'African grey', 'macaw', 'sulphur-crested cockatoo', 'lorikeet', 'coucal', 'bee eater', 'hornbill', 'hummingbird', 'jacamar', 'toucan', 'drake', 'red-breasted merganser', 'goose', 'black swan', 'tusker', 'echidna', 'platypus', 'wallaby', 'koala', 'wombat', 'jellyfish', 'sea anemone', 'brain coral', 'flatworm', 'nematode', 'conch', 'snail', 'slug', 'sea slug', 'chiton', 'chambered nautilus', 'Dungeness crab', 'rock crab', 'fiddler crab', 'king crab', 'American lobster', 'spiny lobster', 'crayfish', 'hermit crab', 'isopod', 'white stork', 'black stork', 'spoonbill', 'flamingo', 'little blue heron', 'American egret', 'bittern', 'crane', 'limpkin', 'European gallinule', 'American coot', 'bustard', 'ruddy turnstone', 'red-backed sandpiper', 'redshank', 'dowitcher', 'oystercatcher', 'pelican', 'king penguin', 'albatross', 'grey whale', 'killer whale', 'dugong', 'sea lion', 'Chihuahua', 'Japanese spaniel', 'Maltese dog', 'Pekinese', 'Shih-Tzu', 'Blenheim spaniel', 'papillon', 'toy terrier', 'Rhodesian ridgeback', 'Afghan hound', 'basset', 'beagle', 'bloodhound', 'bluetick', 'black-and-tan coonhound', 'Walker hound', 'English foxhound', 'redbone', 'borzoi', 'Irish wolfhound', 'Italian greyhound', 'whippet', 'Ibizan hound', 'Norwegian elkhound', 'otterhound', 'Saluki', 'Scottish deerhound', 'Weimaraner', 'Staffordshire bullterrier', 'American Staffordshire terrier', 'Bedlington terrier', 'Border terrier', 'Kerry blue terrier', 'Irish terrier', 'Norfolk terrier', 'Norwich terrier', 'Yorkshire terrier', 'wire-haired fox terrier', 'Lakeland terrier', 'Sealyham terrier', 'Airedale', 'cairn', 'Australian terrier', 'Dandie Dinmont', 'Boston bull', 'miniature schnauzer', 'giant schnauzer', 'standard schnauzer', 'Scotch terrier', 'Tibetan terrier', 'silky terrier', 'soft-coated wheaten terrier', 'West Highland white terrier', 'Lhasa', 'flat-coated retriever', 'curly-coated retriever', 'golden retriever', 'Labrador retriever', 'Chesapeake Bay retriever', 'German short-haired pointer', 'vizsla', 'English setter', 'Irish setter', 'Gordon setter', 'Brittany spaniel', 'clumber', 'English springer', 'Welsh springer spaniel', 'cocker spaniel', 'Sussex spaniel', 'Irish water spaniel', 'kuvasz', 'schipperke', 'groenendael', 'malinois', 'briard', 'kelpie', 'komondor', 'Old English sheepdog', 'Shetland sheepdog', 'collie', 'Border collie', 'Bouvier des Flandres', 'Rottweiler', 'German shepherd', 'Doberman', 'miniature pinscher', 'Greater Swiss Mountain dog', 'Bernese mountain dog', 'Appenzeller', 'EntleBucher', 'boxer', 'bull mastiff', 'Tibetan mastiff', 'French bulldog', 'Great Dane', 'Saint Bernard', 'Eskimo dog', 'malamute', 'Siberian husky', 'dalmatian', 'affenpinscher', 'basenji', 'pug', 'Leonberg', 'Newfoundland', 'Great Pyrenees', 'Samoyed', 'Pomeranian', 'chow', 'keeshond', 'Brabancon griffon', 'Pembroke', 'Cardigan', 'toy poodle', 'miniature poodle', 'standard poodle', 'Mexican hairless', 'timber wolf', 'white wolf', 'red wolf', 'coyote', 'dingo', 'dhole', 'African hunting dog', 'hyena', 'red fox', 'kit fox', 'Arctic fox', 'grey fox', 'tabby', 'tiger cat', 'Persian cat', 'Siamese cat', 'Egyptian cat', 'cougar', 'lynx', 'leopard', 'snow leopard', 'jaguar', 'lion', 'tiger', 'cheetah', 'brown bear', 'American black bear', 'ice bear', 'sloth bear', 'mongoose', 'meerkat', 'tiger beetle', 'ladybug', 'ground beetle', 'long-horned beetle', 'leaf beetle', 'dung beetle', 'rhinoceros beetle', 'weevil', 'fly', 'bee', 'ant', 'grasshopper', 'cricket', 'walking stick', 'cockroach', 'mantis', 'cicada', 'leafhopper', 'lacewing', 'dragonfly', 'damselfly', 'admiral', 'ringlet', 'monarch', 'cabbage butterfly', 'sulphur butterfly', 'lycaenid', 'starfish', 'sea urchin', 'sea cucumber', 'wood rabbit', 'hare', 'Angora', 'hamster', 'porcupine', 'fox squirrel', 'marmot', 'beaver', 'guinea pig', 'sorrel', 'zebra', 'hog', 'wild boar', 'warthog', 'hippopotamus', 'ox', 'water buffalo', 'bison', 'ram', 'bighorn', 'ibex', 'hartebeest', 'impala', 'gazelle', 'Arabian camel', 'llama', 'weasel', 'mink', 'polecat', 'black-footed ferret', 'otter', 'skunk', 'badger', 'armadillo', 'three-toed sloth', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'siamang', 'guenon', 'patas', 'baboon', 'macaque', 'langur', 'colobus', 'proboscis monkey', 'marmoset', 'capuchin', 'howler monkey', 'titi', 'spider monkey', 'squirrel monkey', 'Madagascar cat', 'indri', 'Indian elephant', 'African elephant', 'lesser panda', 'giant panda', 'barracouta', 'eel', 'coho', 'rock beauty', 'anemone fish', 'sturgeon', 'gar', 'lionfish', 'puffer', 'abacus', 'abaya', 'academic gown', 'accordion', 'acoustic guitar', 'aircraft carrier', 'airliner', 'airship', 'altar', 'ambulance', 'amphibian', 'analog clock', 'apiary', 'apron', 'ashcan', 'assault rifle', 'backpack', 'bakery', 'balance beam', 'balloon', 'ballpoint', 'Band Aid', 'banjo', 'bannister', 'barbell', 'barber chair', 'barbershop', 'barn', 'barometer', 'barrel', 'barrow', 'baseball', 'basketball', 'bassinet', 'bassoon', 'bathing cap', 'bath towel', 'bathtub', 'beach wagon', 'beacon', 'beaker', 'bearskin', 'beer bottle', 'beer glass', 'bell cote', 'bib', 'bicycle-built-for-two', 'bikini', 'binder', 'binoculars', 'birdhouse', 'boathouse', 'bobsled', 'bolo tie', 'bonnet', 'bookcase', 'bookshop', 'bottlecap', 'bow', 'bow tie', 'brass', 'brassiere', 'breakwater', 'breastplate', 'broom', 'bucket', 'buckle', 'bulletproof vest', 'bullet train', 'butcher shop', 'cab', 'caldron', 'candle', 'cannon', 'canoe', 'can opener', 'cardigan', 'car mirror', 'carousel', \"carpenter's kit\", 'carton', 'car wheel', 'cash machine', 'cassette', 'cassette player', 'castle', 'catamaran', 'CD player', 'cello', 'cellular telephone', 'chain', 'chainlink fence', 'chain mail', 'chain saw', 'chest', 'chiffonier', 'chime', 'china cabinet', 'Christmas stocking', 'church', 'cinema', 'cleaver', 'cliff dwelling', 'cloak', 'clog', 'cocktail shaker', 'coffee mug', 'coffeepot', 'coil', 'combination lock', 'computer keyboard', 'confectionery', 'container ship', 'convertible', 'corkscrew', 'cornet', 'cowboy boot', 'cowboy hat', 'cradle', 'crane', 'crash helmet', 'crate', 'crib', 'Crock Pot', 'croquet ball', 'crutch', 'cuirass', 'dam', 'desk', 'desktop computer', 'dial telephone', 'diaper', 'digital clock', 'digital watch', 'dining table', 'dishrag', 'dishwasher', 'disk brake', 'dock', 'dogsled', 'dome', 'doormat', 'drilling platform', 'drum', 'drumstick', 'dumbbell', 'Dutch oven', 'electric fan', 'electric guitar', 'electric locomotive', 'entertainment center', 'envelope', 'espresso maker', 'face powder', 'feather boa', 'file', 'fireboat', 'fire engine', 'fire screen', 'flagpole', 'flute', 'folding chair', 'football helmet', 'forklift', 'fountain', 'fountain pen', 'four-poster', 'freight car', 'French horn', 'frying pan', 'fur coat', 'garbage truck', 'gasmask', 'gas pump', 'goblet', 'go-kart', 'golf ball', 'golfcart', 'gondola', 'gong', 'gown', 'grand piano', 'greenhouse', 'grille', 'grocery store', 'guillotine', 'hair slide', 'hair spray', 'half track', 'hammer', 'hamper', 'hand blower', 'hand-held computer', 'handkerchief', 'hard disc', 'harmonica', 'harp', 'harvester', 'hatchet', 'holster', 'home theater', 'honeycomb', 'hook', 'hoopskirt', 'horizontal bar', 'horse cart', 'hourglass', 'iPod', 'iron', \"jack-o'-lantern\", 'jean', 'jeep', 'jersey', 'jigsaw puzzle', 'jinrikisha', 'joystick', 'kimono', 'knee pad', 'knot', 'lab coat', 'ladle', 'lampshade', 'laptop', 'lawn mower', 'lens cap', 'letter opener', 'library', 'lifeboat', 'lighter', 'limousine', 'liner', 'lipstick', 'Loafer', 'lotion', 'loudspeaker', 'loupe', 'lumbermill', 'magnetic compass', 'mailbag', 'mailbox', 'maillot', 'maillot', 'manhole cover', 'maraca', 'marimba', 'mask', 'matchstick', 'maypole', 'maze', 'measuring cup', 'medicine chest', 'megalith', 'microphone', 'microwave', 'military uniform', 'milk can', 'minibus', 'miniskirt', 'minivan', 'missile', 'mitten', 'mixing bowl', 'mobile home', 'Model T', 'modem', 'monastery', 'monitor', 'moped', 'mortar', 'mortarboard', 'mosque', 'mosquito net', 'motor scooter', 'mountain bike', 'mountain tent', 'mouse', 'mousetrap', 'moving van', 'muzzle', 'nail', 'neck brace', 'necklace', 'nipple', 'notebook', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil filter', 'organ', 'oscilloscope', 'overskirt', 'oxcart', 'oxygen mask', 'packet', 'paddle', 'paddlewheel', 'padlock', 'paintbrush', 'pajama', 'palace', 'panpipe', 'paper towel', 'parachute', 'parallel bars', 'park bench', 'parking meter', 'passenger car', 'patio', 'pay-phone', 'pedestal', 'pencil box', 'pencil sharpener', 'perfume', 'Petri dish', 'photocopier', 'pick', 'pickelhaube', 'picket fence', 'pickup', 'pier', 'piggy bank', 'pill bottle', 'pillow', 'ping-pong ball', 'pinwheel', 'pirate', 'pitcher', 'plane', 'planetarium', 'plastic bag', 'plate rack', 'plow', 'plunger', 'Polaroid camera', 'pole', 'police van', 'poncho', 'pool table', 'pop bottle', 'pot', \"potter's wheel\", 'power drill', 'prayer rug', 'printer', 'prison', 'projectile', 'projector', 'puck', 'punching bag', 'purse', 'quill', 'quilt', 'racer', 'racket', 'radiator', 'radio', 'radio telescope', 'rain barrel', 'recreational vehicle', 'reel', 'reflex camera', 'refrigerator', 'remote control', 'restaurant', 'revolver', 'rifle', 'rocking chair', 'rotisserie', 'rubber eraser', 'rugby ball', 'rule', 'running shoe', 'safe', 'safety pin', 'saltshaker', 'sandal', 'sarong', 'sax', 'scabbard', 'scale', 'school bus', 'schooner', 'scoreboard', 'screen', 'screw', 'screwdriver', 'seat belt', 'sewing machine', 'shield', 'shoe shop', 'shoji', 'shopping basket', 'shopping cart', 'shovel', 'shower cap', 'shower curtain', 'ski', 'ski mask', 'sleeping bag', 'slide rule', 'sliding door', 'slot', 'snorkel', 'snowmobile', 'snowplow', 'soap dispenser', 'soccer ball', 'sock', 'solar dish', 'sombrero', 'soup bowl', 'space bar', 'space heater', 'space shuttle', 'spatula', 'speedboat', 'spider web', 'spindle', 'sports car', 'spotlight', 'stage', 'steam locomotive', 'steel arch bridge', 'steel drum', 'stethoscope', 'stole', 'stone wall', 'stopwatch', 'stove', 'strainer', 'streetcar', 'stretcher', 'studio couch', 'stupa', 'submarine', 'suit', 'sundial', 'sunglass', 'sunglasses', 'sunscreen', 'suspension bridge', 'swab', 'sweatshirt', 'swimming trunks', 'swing', 'switch', 'syringe', 'table lamp', 'tank', 'tape player', 'teapot', 'teddy', 'television', 'tennis ball', 'thatch', 'theater curtain', 'thimble', 'thresher', 'throne', 'tile roof', 'toaster', 'tobacco shop', 'toilet seat', 'torch', 'totem pole', 'tow truck', 'toyshop', 'tractor', 'trailer truck', 'tray', 'trench coat', 'tricycle', 'trimaran', 'tripod', 'triumphal arch', 'trolleybus', 'trombone', 'tub', 'turnstile', 'typewriter keyboard', 'umbrella', 'unicycle', 'upright', 'vacuum', 'vase', 'vault', 'velvet', 'vending machine', 'vestment', 'viaduct', 'violin', 'volleyball', 'waffle iron', 'wall clock', 'wallet', 'wardrobe', 'warplane', 'washbasin', 'washer', 'water bottle', 'water jug', 'water tower', 'whiskey jug', 'whistle', 'wig', 'window screen', 'window shade', 'Windsor tie', 'wine bottle', 'wing', 'wok', 'wooden spoon', 'wool', 'worm fence', 'wreck', 'yawl', 'yurt', 'web site', 'comic book', 'crossword puzzle', 'street sign', 'traffic light', 'book jacket', 'menu', 'plate', 'guacamole', 'consomme', 'hot pot', 'trifle', 'ice cream', 'ice lolly', 'French loaf', 'bagel', 'pretzel', 'cheeseburger', 'hotdog', 'mashed potato', 'head cabbage', 'broccoli', 'cauliflower', 'zucchini', 'spaghetti squash', 'acorn squash', 'butternut squash', 'cucumber', 'artichoke', 'bell pepper', 'cardoon', 'mushroom', 'Granny Smith', 'strawberry', 'orange', 'lemon', 'fig', 'pineapple', 'banana', 'jackfruit', 'custard apple', 'pomegranate', 'hay', 'carbonara', 'chocolate sauce', 'dough', 'meat loaf', 'pizza', 'potpie', 'burrito', 'red wine', 'espresso', 'cup', 'eggnog', 'alp', 'bubble', 'cliff', 'coral reef', 'geyser', 'lakeside', 'promontory', 'sandbar', 'seashore', 'valley', 'volcano', 'ballplayer', 'groom', 'scuba diver', 'rapeseed', 'daisy', \"yellow lady's slipper\", 'corn', 'acorn', 'hip', 'buckeye', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn', 'earthstar', 'hen-of-the-woods', 'bolete', 'ear', 'toilet tissue']\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9NS777mJ22e"
      },
      "source": [
        "the top-5 predictions class names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdaY6OK-Jt_H",
        "outputId": "318d90c9-6435-4950-c5ce-0f86aa7ea6c2"
      },
      "source": [
        "\n",
        "# Print top categories per image\n",
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "#print(top5_prob)\n",
        "#print(top5_catid)\n",
        "print(top5_prob.size(0))\n",
        "print(len(top5_prob))\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
        "    #print(categories[top5_catid[i]], top5_prob[i])  # avoid result  as:   Samoyed   tensor(0.9478)\n",
        "# prints class names and probabilities like:\n",
        "# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n",
            "Samoyed 0.947767972946167\n",
            "Pomeranian 0.008878438733518124\n",
            "Arctic fox 0.006980232894420624\n",
            "keeshond 0.0065886895172297955\n",
            "white wolf 0.0050971307791769505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PLZyleKF5d1",
        "outputId": "849875d5-e42e-44f1-a318-c2af3accbd6d"
      },
      "source": [
        "#All of the models in timm have consistent mechanisms for obtaining various types of features from the model for tasks besides classification.\n",
        "#Penultimate Layer Features (Pre-Classifier Features)\n",
        "#1_Unpooled\n",
        "#method_1#forward_features()\n",
        "\n",
        "import torch\n",
        "import timm\n",
        "m = timm.create_model('xception41', pretrained=True)\n",
        "o = m(torch.randn(2, 3, 299, 299))\n",
        "print(f'Original shape: {o.shape}')\n",
        "o = m.forward_features(torch.randn(2, 3, 299, 299))\n",
        "print(f'Unpooled shape: {o.shape}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape: torch.Size([2, 1000])\n",
            "Unpooled shape: torch.Size([2, 2048, 10, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJpfYrPHHGWe",
        "outputId": "1359197e-9481-400a-f360-517e1efd9ff8"
      },
      "source": [
        "#All of the models in timm have consistent mechanisms for obtaining various types of features from the model for tasks besides classification.\n",
        "#Penultimate Layer Features (Pre-Classifier Features)\n",
        "#1_Unpooled\n",
        "#method_1#Create with no classifier and pooling\n",
        "import torch\n",
        "import timm\n",
        "m = timm.create_model('resnet50', pretrained=True, num_classes=0, global_pool='')\n",
        "o = m(torch.randn(2, 3, 224, 224))\n",
        "print(f'Unpooled shape: {o.shape}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet50_ram-a26f946b.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_ram-a26f946b.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Unpooled shape: torch.Size([2, 2048, 7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc-AE7t6JAuG",
        "outputId": "99807e7c-9318-47ce-da1d-7d56fd9b0ef9"
      },
      "source": [
        "#All of the models in timm have consistent mechanisms for obtaining various types of features from the model for tasks besides classification.\n",
        "#Penultimate Layer Features (Pre-Classifier Features)\n",
        "#1_Unpooled\n",
        "#method_2# #Remove it later\n",
        "import torch\n",
        "import timm\n",
        "m = timm.create_model('densenet121', pretrained=True)\n",
        "o = m(torch.randn(2, 3, 224, 224))\n",
        "print(f'Original shape: {o.shape}')\n",
        "m.reset_classifier(0, '')\n",
        "o = m(torch.randn(2, 3, 224, 224))\n",
        "print(f'Unpooled shape: {o.shape}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/densenet121_ra-50efcf5c.pth\" to /root/.cache/torch/hub/checkpoints/densenet121_ra-50efcf5c.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original shape: torch.Size([2, 1000])\n",
            "Unpooled shape: torch.Size([2, 1024, 7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e41E1mFmJP2j",
        "outputId": "bfd9c5ad-aebc-4f66-d763-9ffb4bcdfc3a"
      },
      "source": [
        "#All of the models in timm have consistent mechanisms for obtaining various types of features from the model for tasks besides classification.\n",
        "#Penultimate Layer Features (Pre-Classifier Features)\n",
        "#2_pooled##Create with no classifier\n",
        "import torch\n",
        "import timm\n",
        "m = timm.create_model('resnet50', pretrained=True, num_classes=0)\n",
        "o = m(torch.randn(2, 3, 224, 224))\n",
        "print(f'Pooled shape: {o.shape}')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pooled shape: torch.Size([2, 2048])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgoxbXdNKOgu",
        "outputId": "5c4adc98-6caa-4c4a-ad84-a152a073d1e2"
      },
      "source": [
        "#All of the models in timm have consistent mechanisms for obtaining various types of features from the model for tasks besides classification.\n",
        "#Penultimate Layer Features (Pre-Classifier Features)\n",
        "#2_pooled##Remove it later\n",
        "\n",
        "import torch\n",
        "import timm\n",
        "m = timm.create_model('ese_vovnet19b_dw', pretrained=True)\n",
        "o = m(torch.randn(2, 3, 224, 224))\n",
        "print(f'Original shape: {o.shape}')\n",
        "m.reset_classifier(0)\n",
        "o = m(torch.randn(2, 3, 224, 224))\n",
        "print(f'Pooled shape: {o.shape}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ese_vovnet19b_dw-a8741004.pth\" to /root/.cache/torch/hub/checkpoints/ese_vovnet19b_dw-a8741004.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original shape: torch.Size([2, 1000])\n",
            "Pooled shape: torch.Size([2, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZSwiaDRGeKA",
        "outputId": "358e4dd4-87bd-47e8-b091-daf10062b5c6"
      },
      "source": [
        "#Multi-scale Feature Maps (Feature Pyramid)\n",
        "#backbone network at multiple scales.\n",
        "#A feature backbone can be created by adding the argument features_only=True to any create_model call. By default 5 strides will be output from most models (not all have that many), with the first starting at 2 (some start at 1 or 4).\n",
        "#Create a feature map extraction model:\n",
        "import torch\n",
        "import timm\n",
        "m = timm.create_model('resnest26d', features_only=True, pretrained=True)\n",
        "o = m(torch.randn(2, 3, 224, 224))\n",
        "for x in o:\n",
        "  print(x.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_resnest26-50eb607c.pth\" to /root/.cache/torch/hub/checkpoints/gluon_resnest26-50eb607c.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 64, 112, 112])\n",
            "torch.Size([2, 256, 56, 56])\n",
            "torch.Size([2, 512, 28, 28])\n",
            "torch.Size([2, 1024, 14, 14])\n",
            "torch.Size([2, 2048, 7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiJNYvT1OEsF",
        "outputId": "ab121fce-4c4c-4f05-9fc0-c99581d02eb3"
      },
      "source": [
        "#Multi-scale Feature Maps (Feature Pyramid)\n",
        "#backbone network at multiple scales.\n",
        "#A feature backbone can be created by adding the argument features_only=True to any create_model call. By default 5 strides will be output from most models (not all have that many), with the first starting at 2 (some start at 1 or 4).\n",
        "#Query the feature information:\n",
        "#After a feature backbone has been created, it can be queried to provide channel or resolution reduction information to the downstream heads without requiring static config or hardcoded constants.\n",
        "# The .feature_info attribute is a class encapsulating the information about the feature extraction points:\n",
        "import torch\n",
        "import timm\n",
        "m = timm.create_model('regnety_032', features_only=True, pretrained=True)\n",
        "print(f'Feature channels: {m.feature_info.channels()}')\n",
        "o = m(torch.randn(2, 3, 224, 224))\n",
        "for x in o:\n",
        "  print(x.shape)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/regnety_032_ra-7f2439f9.pth\" to /root/.cache/torch/hub/checkpoints/regnety_032_ra-7f2439f9.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Feature channels: [32, 72, 216, 576, 1512]\n",
            "torch.Size([2, 32, 112, 112])\n",
            "torch.Size([2, 72, 56, 56])\n",
            "torch.Size([2, 216, 28, 28])\n",
            "torch.Size([2, 576, 14, 14])\n",
            "torch.Size([2, 1512, 7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwFlCJhJOgdS",
        "outputId": "4b3231bb-bbd7-4756-dfc2-88783131f36d"
      },
      "source": [
        "#Select specific feature levels or limit the stride\n",
        "#There are to additional creation arguments impacting the output features.\n",
        "\n",
        "#out_indices selects which indices to output\n",
        "#output_stride limits the feature output stride of the network (also works in classification mode BTW)\n",
        "#out_indices is supported by all models, but not all models have the same index to feature stride mapping. Look at the code or check feature_info to compare. The out indices generally correspond to the C(i+1)th feature level (a 2^(i+1) reduction). For most models, index 0 is the stride 2 features, and index 4 is stride 32.\n",
        "#output_stride is achieved by converting layers to use dilated convolutions. Doing so is not always straightforward, some networks only support output_stride=32.\n",
        "\n",
        "import torch\n",
        "import timm\n",
        "m = timm.create_model('ecaresnet101d', features_only=True, output_stride=8, out_indices=(2, 4), pretrained=True)\n",
        "print(f'Feature channels: {m.feature_info.channels()}')\n",
        "print(f'Feature reduction: {m.feature_info.reduction()}')\n",
        "o = m(torch.randn(2, 3, 320, 320))\n",
        "for x in o:\n",
        "  print(x.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://imvl-automl-sh.oss-cn-shanghai.aliyuncs.com/darts/hyperml/hyperml/job_45402/outputs/ECAResNet101D_281c5844.pth\" to /root/.cache/torch/hub/checkpoints/ECAResNet101D_281c5844.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Feature channels: [512, 2048]\n",
            "Feature reduction: [8, 8]\n",
            "torch.Size([2, 512, 40, 40])\n",
            "torch.Size([2, 2048, 40, 40])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LLbOYBHS11D"
      },
      "source": [
        "#How do I finetune this model?\n",
        "model = timm.create_model('resnetv2_101x1_bitm', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)\n",
        "\n",
        "\n",
        "#To finetune on your own dataset, you have to write a training loop or adapt timm's training script to use your dataset.\n",
        "                                             #https://rwightman.github.io/pytorch-image-models/scripts/\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4X7ofwTVkwM"
      },
      "source": [
        "#How do I train this model?\n",
        "    #You can follow the timm recipe scripts for training a new model afresh: https://rwightman.github.io/pytorch-image-models/scripts/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTS-kAl4TBoq"
      },
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "model =AutoModelForImageClassification.from_pretrained(\"\")\n",
        "\n",
        "model.save_pretrained(\"/content/test_timm_succeed\")\n",
        "model.push_to_hub(\"test-timm\",use_auth_token=\"IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtEL6RyHYYZX"
      },
      "source": [
        "You will need an authentication token with your Hugging Face credentials to use the `push_to_hub` method. Execute `huggingface-cli login` in your terminal or by uncommenting the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDESuzoOYYZv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEMiXvPCYYZ9"
      },
      "source": [
        "checkpoint = \"bert-base-cased\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er7be2xTYYaI"
      },
      "source": [
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True)\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    \"finetuned-bert-mrpc\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    log_level=\"error\",\n",
        "    push_to_hub=True,\n",
        "    push_to_hub_model_id=\"finetuned-bert-mrpc\",\n",
        "    # push_to_hub_organization=\"huggingface\",\n",
        "     push_to_hub_token=\"IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk\",\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "metric = load_metric(\"glue\", \"mrpc\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4nfFFPFYYaj"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2jBGezSYYar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "2296bfb4-7869-4322-fba6-f4d4344088a3"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [690/690 03:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.570400</td>\n",
              "      <td>0.420420</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.854202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.415668</td>\n",
              "      <td>0.845588</td>\n",
              "      <td>0.895522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.192300</td>\n",
              "      <td>0.528038</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.900332</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=690, training_loss=0.36729109390922215, metrics={'train_runtime': 180.7776, 'train_samples_per_second': 60.87, 'train_steps_per_second': 3.817, 'total_flos': 445479905606400.0, 'train_loss': 0.36729109390922215, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRR-pyhjYYax"
      },
      "source": [
        "## Push to hub from the Trainer directly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs2cwKq3YYa2"
      },
      "source": [
        "The `Trainer` has a new method to directly upload the model, tokenizer and model configuration in a repo on the [Hub](https://huggingface.co/). It will even auto-generate a model card draft using the hyperparameters and evaluation results!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaL5BMI_YYa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "abda0883-1f1f-4991-adff-25d26cb38fa5"
      },
      "source": [
        "trainer.push_to_hub()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://huggingface.co/oumeima/finetuned-bert-mrpc/commit/63d0302ab1d8709b53bf0e216b486d95647ede77'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c71WzGWAYYbF"
      },
      "source": [
        "If you are using your own training loop, you can push the model and tokenizer separately (and you will have to write the model card yourself):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LplgDhbeYYbI"
      },
      "source": [
        "# model.push_to_hub(\"finetuned-bert-mrpc\")\n",
        "# tokenizer.push_to_hub(\"finetuned-bert-mrpc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOefTQmpYYbK"
      },
      "source": [
        "## You can load your model from anywhere using from_pretrained!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owz0d5NcYYbM"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"sgugger/finetuned-bert-mrpc\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy2RJFAgYYbV"
      },
      "source": [
        "## You can use your model in a pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTR0Wm5ZYYbX"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFrEtIOgYYbb"
      },
      "source": [
        "classifier(\"My name is Sylvain. [SEP] My name is Lysandre\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJYJpbQ7YYcc"
      },
      "source": [
        "## Updating a problematic file is super easy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b_v4RFcYYcr"
      },
      "source": [
        "model.config.label2id = {\"not equivalent\": 0, \"equivalent\": 1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oza5K_lwYYcu"
      },
      "source": [
        "model.config.id2label = {0: \"not equivalent\", 1: \"equivalent\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwZs7j_vYYcw"
      },
      "source": [
        "model.config.push_to_hub(\"finetuned-bert-mrpc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NHEqUNP4YYc2"
      },
      "source": [
        "classifier = pipeline(\"text-classification\", model=model_name)\n",
        "\n",
        "classifier(\"My name is Sylvain. [SEP] My name is Lysandre\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbcbv708YYc5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}