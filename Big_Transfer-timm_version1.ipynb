{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Copie de Copie de The push to hub API",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oumeimaghnimi/Huggingface_hub_learning/blob/master/Big_Transfer-timm_version1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-mdMSdBYYXt"
      },
      "source": [
        "This notebook tries to instantiate the code sample of timm repository:\n",
        "https://rwightman.github.io/pytorch-image-models/models/big-transfer/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJkkvwtmeSKl",
        "outputId": "30bec70f-4ea8-4d7a-b1e6-4e624315fa01"
      },
      "source": [
        "!pip install  datasets transformers[sentencepiece]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.7.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.45)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (5.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.10.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.91)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7r1XXs-kAnW",
        "outputId": "e04fb5e5-2724-44c2-d448-cfefb3b5e979"
      },
      "source": [
        "!python -m pip install --upgrade pip; pip install git-lfs\n",
        "#git lfs install\n",
        "!apt-get install git-lfs"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.2.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: git-lfs in /usr/local/lib/python3.7/dist-packages (1.6)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUt0-iW8uaDW"
      },
      "source": [
        "!git config --global user.email \"oumeimaghnimi29@gmail.com\"\n",
        "!git config --global user.name \"oumeima\""
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU8OK--uuPQZ",
        "outputId": "2f5d6d50-fda7-4ed6-f4d2-6019c7e13b33"
      },
      "source": [
        "!huggingface-cli login\n",
        "#!transformers-cli login"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        \n",
            "Username: oumeima\n",
            "Password: \n",
            "Login successful\n",
            "Your token: IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk \n",
            "\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1e12HQX-Cs4"
      },
      "source": [
        "!huggingface-cli repo create test_timm_succeed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjAPFJ9n_cbU",
        "outputId": "008b45f8-d7b0-4fce-f573-fba9cabf24ba"
      },
      "source": [
        " !git clone https://huggingface.co/oumeima/test_timm_succeed"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'test_timm_succeed'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0)\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmaO0wgl_mI4",
        "outputId": "a2c0d3d3-cc24-4563-b7a6-f67ff9e871f7"
      },
      "source": [
        "!cd test_timm_succeed && ls"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Big Transfer (BiT)_timm_test_to_huggingface.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMGVTtdQWazK",
        "outputId": "27884368-bdcb-4332-ed87-25fe855b7203"
      },
      "source": [
        "!huggingface-cli  whoami  "
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "oumeima\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luyyKvrtMtyo",
        "outputId": "413620be-d1b4-446f-b5d0-c019849f0011"
      },
      "source": [
        "!cd /content/test_timm_succeed; git add . ; git status;   git commit -m \"First pretrained BiT version\",\n",
        "!cd /content/test_timm_succeed; git push  \"https://IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk@https://huggingface.co/oumeima /test-timm-succeed.git\"\n",
        "\n",
        "#!cd /content/test_timm_succeed; set :repository,  \"https://IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk@https://huggingface.co/oumeima /application.git\"; git push\n",
        "#!cd /content/test_timm_succeed; git push -f origin main  \n",
        "#\"https://IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk@https://huggingface.co/oumeima \n",
        "\n",
        "#git lfs status, \n",
        "\n",
        " #set :repository,  \"https://<OAuthToken>@github.com/username/application.git\"\n",
        " #git push \"https://$GITHUB_ACTOR:$GITHUB_TOKEN@github.com/$INPUT_REPO.git\" gh-pages\n",
        "#https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners#github_token-secret:\n",
        " #Hey, I was able to get this working.  Here is an example: https://github.com/pkgjs/gh-pages/blob/master/entrypoint.sh Basically there are two environment vars you can use GITHUB_ACTOR and GITHUB_TOKEN.  Then use the https push url.  To get the token passed in you need to use the secrets as documen…"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "fatal: unable to access 'https://IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk@https://huggingface.co/oumeima /test-timm-succeed.git/': Could not resolve host: https\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9jFonjxPMi5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "S26uqAuDCTuJ",
        "outputId": "6c7eec1d-9ff7-4773-f57b-2ee72acf2ef4"
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7q8dNsoekLB",
        "outputId": "9814b60a-b318-4ea9-e2ae-10d9eb61df11"
      },
      "source": [
        "!pip install  timm"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.4.12)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCiBDhbHfOYq"
      },
      "source": [
        "import timm"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JainiVzJ7tau"
      },
      "source": [
        "load a pretrained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUVVGG5Fgj8v",
        "outputId": "4cfcc358-eae5-4adc-b840-f15bd7e732f9"
      },
      "source": [
        "\n",
        "model = timm.create_model('resnetv2_101x1_bitm', pretrained=True)\n",
        "model.eval()\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetV2(\n",
              "  (stem): Sequential(\n",
              "    (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (pad): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (stages): Sequential(\n",
              "    (0): ResNetStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): PreActBottleneck(\n",
              "          (downsample): DownsampleConv(\n",
              "            (conv): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (norm): Identity()\n",
              "          )\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 64, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): ResNetStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): PreActBottleneck(\n",
              "          (downsample): DownsampleConv(\n",
              "            (conv): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (norm): Identity()\n",
              "          )\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 128, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): ResNetStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): PreActBottleneck(\n",
              "          (downsample): DownsampleConv(\n",
              "            (conv): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (norm): Identity()\n",
              "          )\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (8): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (9): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (10): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (11): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (12): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (13): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (14): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (15): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (16): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (17): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (18): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (19): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (20): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (21): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (22): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 256, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): ResNetStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): PreActBottleneck(\n",
              "          (downsample): DownsampleConv(\n",
              "            (conv): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (norm): Identity()\n",
              "          )\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 1024, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 2048, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): PreActBottleneck(\n",
              "          (norm1): GroupNormAct(\n",
              "            32, 2048, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (norm3): GroupNormAct(\n",
              "            32, 512, eps=1e-05, affine=True\n",
              "            (act): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (norm): GroupNormAct(\n",
              "    32, 2048, eps=1e-05, affine=True\n",
              "    (act): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): ClassifierHead(\n",
              "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
              "    (fc): Conv2d(2048, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZx0DRPrCLlZ"
      },
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "model =AutoModelForImageClassification.from_pretrained(\"\")\n",
        "\n",
        "model.save_pretrained(\"/content/test_timm_succeed\")\n",
        "model.push_to_hub(\"test-timm\",use_auth_token=\"IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwx8oSjh7P1B"
      },
      "source": [
        "load and preprocess the image: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJxpNdkmhTB1"
      },
      "source": [
        "import urllib\n",
        "from PIL import Image\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QrKVvIohXeQ",
        "outputId": "a26e4a27-1d87-4e98-cd2f-a1e29c8a6e52"
      },
      "source": [
        "config = resolve_data_config({}, model=model)\n",
        "transform = create_transform(**config)\n",
        "\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "img = Image.open(filename).convert('RGB')\n",
        "tensor = transform(img).unsqueeze(0) # transform and add batch dimension"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM411fEdigu5"
      },
      "source": [
        "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
        "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
        "\n",
        "  trial to correct the error:\n",
        "  https://github.com/pytorch/vision/blob/master/torchvision/transforms/transforms.py:\n",
        "  from .functional import InterpolationMode, _interpolation_modes_from_int\n",
        "\n",
        "   \n",
        "   line 281: /usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281:\n",
        "    \n",
        "                  or\n",
        "\n",
        "   line 387: in https://github.com/pytorch/vision/blob/master/torchvision/transforms/functional.py\n",
        "   \n",
        "   (it is not an error, just an information error):\n",
        "     if isinstance(interpolation, int):\n",
        "           warnings.warn(\n",
        "               \"Argument interpolation should be of type InterpolationMode      instead of int. \"\n",
        "            \"Please, use InterpolationMode enum.\"\n",
        "        )\n",
        "        interpolation = _interpolation_modes_from_int(interpolation)\n",
        "\n",
        "\n",
        "\n",
        "interpolation as an argument \n",
        "\n",
        "\n",
        "https://github.com/pytorch/vision/blob/master/torchvision/transforms/functional.py\n",
        "\n",
        "\n",
        "def _interpolation_modes_from_int(i: int) -> InterpolationMode:\n",
        "    inverse_modes_mapping = {\n",
        "        0: InterpolationMode.NEAREST,\n",
        "        2: InterpolationMode.BILINEAR,\n",
        "        3: InterpolationMode.BICUBIC,\n",
        "        4: InterpolationMode.BOX,\n",
        "        5: InterpolationMode.HAMMING,\n",
        "        1: InterpolationMode.LANCZOS,\n",
        "    }\n",
        "    return inverse_modes_mapping[i]\n",
        "\n",
        "\n",
        "pil_modes_mapping = {\n",
        "    InterpolationMode.NEAREST: 0,\n",
        "    InterpolationMode.BILINEAR: 2,\n",
        "    InterpolationMode.BICUBIC: 3,\n",
        "    InterpolationMode.BOX: 4,\n",
        "    InterpolationMode.HAMMING: 5,\n",
        "    InterpolationMode.LANCZOS: 1,\n",
        "}\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "resolve_data_config:\n",
        "    from timm.data import resolve_data_config\n",
        "    \n",
        "def resolve_data_config(args, default_cfg={}, model=None, use_test_size=False, verbose=False):\n",
        "   \n",
        "\n",
        "\n",
        "   timm/data/config.py: \n",
        "    # resolve interpolation method\n",
        "    new_config['interpolation'] = 'bicubic'\n",
        "    if 'interpolation' in args and args['interpolation']:\n",
        "        new_config['interpolation'] = args['interpolation']\n",
        "    elif 'interpolation' in default_cfg:\n",
        "        new_config['interpolation'] = default_cfg['interpolation']   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk26SvZ_MCk0"
      },
      "source": [
        "get the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_ZKGh5JMnyb"
      },
      "source": [
        "import torch\n",
        "with torch.no_grad():\n",
        "    out = model(tensor)\n",
        "probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
        "print(probabilities.shape)\n",
        "# prints: torch.Size([1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtEL6RyHYYZX"
      },
      "source": [
        "You will need an authentication token with your Hugging Face credentials to use the `push_to_hub` method. Execute `huggingface-cli login` in your terminal or by uncommenting the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDESuzoOYYZv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEMiXvPCYYZ9"
      },
      "source": [
        "checkpoint = \"bert-base-cased\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er7be2xTYYaI"
      },
      "source": [
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True)\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    \"finetuned-bert-mrpc\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    log_level=\"error\",\n",
        "    push_to_hub=True,\n",
        "    push_to_hub_model_id=\"finetuned-bert-mrpc\",\n",
        "    # push_to_hub_organization=\"huggingface\",\n",
        "     push_to_hub_token=\"IdlHLMifuinaYGfKtmyBFlCKpztZaHklVWKqXdqRoEUskQkVjXntXYrAfMLLOusJwpovVMlBEDqTqnlEHwHlkdBbAZnyveUmAOAnIxSUOVQZqHiqjqRNMlsJJgyTmGBk\",\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "metric = load_metric(\"glue\", \"mrpc\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4nfFFPFYYaj"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2jBGezSYYar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "2296bfb4-7869-4322-fba6-f4d4344088a3"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [690/690 03:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.570400</td>\n",
              "      <td>0.420420</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.854202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.415668</td>\n",
              "      <td>0.845588</td>\n",
              "      <td>0.895522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.192300</td>\n",
              "      <td>0.528038</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.900332</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=690, training_loss=0.36729109390922215, metrics={'train_runtime': 180.7776, 'train_samples_per_second': 60.87, 'train_steps_per_second': 3.817, 'total_flos': 445479905606400.0, 'train_loss': 0.36729109390922215, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRR-pyhjYYax"
      },
      "source": [
        "## Push to hub from the Trainer directly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs2cwKq3YYa2"
      },
      "source": [
        "The `Trainer` has a new method to directly upload the model, tokenizer and model configuration in a repo on the [Hub](https://huggingface.co/). It will even auto-generate a model card draft using the hyperparameters and evaluation results!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaL5BMI_YYa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "abda0883-1f1f-4991-adff-25d26cb38fa5"
      },
      "source": [
        "trainer.push_to_hub()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://huggingface.co/oumeima/finetuned-bert-mrpc/commit/63d0302ab1d8709b53bf0e216b486d95647ede77'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c71WzGWAYYbF"
      },
      "source": [
        "If you are using your own training loop, you can push the model and tokenizer separately (and you will have to write the model card yourself):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LplgDhbeYYbI"
      },
      "source": [
        "# model.push_to_hub(\"finetuned-bert-mrpc\")\n",
        "# tokenizer.push_to_hub(\"finetuned-bert-mrpc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOefTQmpYYbK"
      },
      "source": [
        "## You can load your model from anywhere using from_pretrained!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owz0d5NcYYbM"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"sgugger/finetuned-bert-mrpc\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy2RJFAgYYbV"
      },
      "source": [
        "## You can use your model in a pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTR0Wm5ZYYbX"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFrEtIOgYYbb"
      },
      "source": [
        "classifier(\"My name is Sylvain. [SEP] My name is Lysandre\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJYJpbQ7YYcc"
      },
      "source": [
        "## Updating a problematic file is super easy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b_v4RFcYYcr"
      },
      "source": [
        "model.config.label2id = {\"not equivalent\": 0, \"equivalent\": 1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oza5K_lwYYcu"
      },
      "source": [
        "model.config.id2label = {0: \"not equivalent\", 1: \"equivalent\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwZs7j_vYYcw"
      },
      "source": [
        "model.config.push_to_hub(\"finetuned-bert-mrpc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NHEqUNP4YYc2"
      },
      "source": [
        "classifier = pipeline(\"text-classification\", model=model_name)\n",
        "\n",
        "classifier(\"My name is Sylvain. [SEP] My name is Lysandre\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbcbv708YYc5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}